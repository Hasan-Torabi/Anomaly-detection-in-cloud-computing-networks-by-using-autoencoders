{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E3 train2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcKEas96clPc",
        "outputId": "5e503e58-7635-451c-fd98-cf5725938017"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwWqO0ADctci",
        "outputId": "035fea25-63eb-4bef-a949-56cbb73f6f50"
      },
      "source": [
        "!pip3 install category_encoders\n",
        "import category_encoders as ce"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.3.0-py2.py3-none-any.whl (82 kB)\n",
            "\u001b[?25l\r\u001b[K     |████                            | 10 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 20 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 30 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 40 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 51 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 61 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 71 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 81 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 82 kB 441 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.3.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##import libraries"
      ],
      "metadata": {
        "id": "EdbnMYiN1eDA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TiJlHnmcrkM"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# import torch.utils.model_zoo as model_zoo\n",
        "# from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import time\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from datetime import timedelta\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4MFLdnyAm5o"
      },
      "source": [
        "\n",
        "!cp /content/drive/\"My Drive\"/e3.csv /content/\n",
        "# !cp /content/drive/\"My Drive\"/e3-scaled-withclass.csv /content/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##read data"
      ],
      "metadata": {
        "id": "2vo-D20m1syg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsMpPXV4Avqj"
      },
      "source": [
        "csvdata = pd.read_csv('e3.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "LiK_cD9QNG9m",
        "outputId": "651d9215-0b96-4627-c3e2-54c0bbcf7f18"
      },
      "source": [
        "#delete irrelevant columns\n",
        "del csvdata['attackType']\n",
        "del csvdata['attackID']\n",
        "del csvdata['attackDescription']\n",
        "del csvdata['Flows']\n",
        "del csvdata['Tos']\n",
        "csvdata"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-52a45dca-90fb-4ba0-9e68-96b2692320a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Duration</th>\n",
              "      <th>Proto</th>\n",
              "      <th>Src IP Addr</th>\n",
              "      <th>Src Pt</th>\n",
              "      <th>Dst IP Addr</th>\n",
              "      <th>Dst Pt</th>\n",
              "      <th>Packets</th>\n",
              "      <th>Flags</th>\n",
              "      <th>class</th>\n",
              "      <th>Bytes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000</td>\n",
              "      <td>TCP</td>\n",
              "      <td>26913_25</td>\n",
              "      <td>43618</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>....S.</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000</td>\n",
              "      <td>TCP</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>23</td>\n",
              "      <td>26913_25</td>\n",
              "      <td>43618.0</td>\n",
              "      <td>1</td>\n",
              "      <td>.A.R..</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000</td>\n",
              "      <td>TCP</td>\n",
              "      <td>26914_116</td>\n",
              "      <td>1817</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>....S.</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000</td>\n",
              "      <td>TCP</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>23</td>\n",
              "      <td>26914_116</td>\n",
              "      <td>1817.0</td>\n",
              "      <td>1</td>\n",
              "      <td>.A.R..</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.001</td>\n",
              "      <td>TCP</td>\n",
              "      <td>26915_202</td>\n",
              "      <td>57272</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>1433.0</td>\n",
              "      <td>1</td>\n",
              "      <td>....S.</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153021</th>\n",
              "      <td>67601.294</td>\n",
              "      <td>TCP</td>\n",
              "      <td>OPENSTACK_NET</td>\n",
              "      <td>49493</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>8082.0</td>\n",
              "      <td>160681</td>\n",
              "      <td>.APRS.</td>\n",
              "      <td>normal</td>\n",
              "      <td>12200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153022</th>\n",
              "      <td>67601.294</td>\n",
              "      <td>TCP</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>8082</td>\n",
              "      <td>OPENSTACK_NET</td>\n",
              "      <td>49494.0</td>\n",
              "      <td>172810</td>\n",
              "      <td>.AP.S.</td>\n",
              "      <td>normal</td>\n",
              "      <td>465700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153023</th>\n",
              "      <td>67601.294</td>\n",
              "      <td>TCP</td>\n",
              "      <td>OPENSTACK_NET</td>\n",
              "      <td>49494</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>8082.0</td>\n",
              "      <td>170412</td>\n",
              "      <td>.APRS.</td>\n",
              "      <td>normal</td>\n",
              "      <td>28500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153024</th>\n",
              "      <td>67601.103</td>\n",
              "      <td>TCP</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>8082</td>\n",
              "      <td>OPENSTACK_NET</td>\n",
              "      <td>49495.0</td>\n",
              "      <td>148533</td>\n",
              "      <td>.AP.S.</td>\n",
              "      <td>normal</td>\n",
              "      <td>394900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153025</th>\n",
              "      <td>67601.103</td>\n",
              "      <td>TCP</td>\n",
              "      <td>OPENSTACK_NET</td>\n",
              "      <td>49495</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>8082.0</td>\n",
              "      <td>147538</td>\n",
              "      <td>.APRS.</td>\n",
              "      <td>normal</td>\n",
              "      <td>29500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153026 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52a45dca-90fb-4ba0-9e68-96b2692320a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52a45dca-90fb-4ba0-9e68-96b2692320a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52a45dca-90fb-4ba0-9e68-96b2692320a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Duration  Proto    Src IP Addr  ...   Flags       class      Bytes\n",
              "0           0.000  TCP         26913_25  ...  ....S.  suspicious         46\n",
              "1           0.000  TCP       EXT_SERVER  ...  .A.R..  suspicious         40\n",
              "2           0.000  TCP        26914_116  ...  ....S.  suspicious         46\n",
              "3           0.000  TCP       EXT_SERVER  ...  .A.R..  suspicious         40\n",
              "4           0.001  TCP        26915_202  ...  ....S.  suspicious         46\n",
              "...           ...    ...            ...  ...     ...         ...        ...\n",
              "153021  67601.294  TCP    OPENSTACK_NET  ...  .APRS.      normal   12200000\n",
              "153022  67601.294  TCP       EXT_SERVER  ...  .AP.S.      normal  465700000\n",
              "153023  67601.294  TCP    OPENSTACK_NET  ...  .APRS.      normal   28500000\n",
              "153024  67601.103  TCP       EXT_SERVER  ...  .AP.S.      normal  394900000\n",
              "153025  67601.103  TCP    OPENSTACK_NET  ...  .APRS.      normal   29500000\n",
              "\n",
              "[153026 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##preprocessing"
      ],
      "metadata": {
        "id": "oDN42OBe20GY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "tAY_HQkKNG7r",
        "outputId": "3548f430-9edd-4c97-b2bb-37f6adfcad8b"
      },
      "source": [
        "#change object values of \"Bytes\" column to int values (for example: 1M -> 1000000)\n",
        "multipliers = {'K':1000, 'M':1000000, 'B':1000000000}\n",
        "\n",
        "def string_to_int(string):\n",
        "  if string.find('M') == -1:\n",
        "      return int(string)\n",
        "  mult = multipliers[string[-1]] # look up suffix to get multiplier\n",
        "  # convert number to float, multiply by multiplier, then make int\n",
        "  return int(float(string[:-1]) * mult)\n",
        "\n",
        "bytes_new = list(map(string_to_int, csvdata['Bytes'].astype('str') ))\n",
        "print(\"len of bytes_new: \", len(bytes_new))\n",
        "\n",
        "del csvdata['Bytes']\n",
        "\n",
        "csvdata['Bytes'] = bytes_new\n",
        "csvdata"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len of bytes_new:  153026\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e2001370-b8a7-4d55-bbce-63647d9711a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Duration</th>\n",
              "      <th>Proto</th>\n",
              "      <th>Src IP Addr</th>\n",
              "      <th>Src Pt</th>\n",
              "      <th>Dst IP Addr</th>\n",
              "      <th>Dst Pt</th>\n",
              "      <th>Packets</th>\n",
              "      <th>Flags</th>\n",
              "      <th>class</th>\n",
              "      <th>Bytes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000</td>\n",
              "      <td>TCP</td>\n",
              "      <td>26913_25</td>\n",
              "      <td>43618</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>....S.</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000</td>\n",
              "      <td>TCP</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>23</td>\n",
              "      <td>26913_25</td>\n",
              "      <td>43618.0</td>\n",
              "      <td>1</td>\n",
              "      <td>.A.R..</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000</td>\n",
              "      <td>TCP</td>\n",
              "      <td>26914_116</td>\n",
              "      <td>1817</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>....S.</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000</td>\n",
              "      <td>TCP</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>23</td>\n",
              "      <td>26914_116</td>\n",
              "      <td>1817.0</td>\n",
              "      <td>1</td>\n",
              "      <td>.A.R..</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.001</td>\n",
              "      <td>TCP</td>\n",
              "      <td>26915_202</td>\n",
              "      <td>57272</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>1433.0</td>\n",
              "      <td>1</td>\n",
              "      <td>....S.</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153021</th>\n",
              "      <td>67601.294</td>\n",
              "      <td>TCP</td>\n",
              "      <td>OPENSTACK_NET</td>\n",
              "      <td>49493</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>8082.0</td>\n",
              "      <td>160681</td>\n",
              "      <td>.APRS.</td>\n",
              "      <td>normal</td>\n",
              "      <td>12200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153022</th>\n",
              "      <td>67601.294</td>\n",
              "      <td>TCP</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>8082</td>\n",
              "      <td>OPENSTACK_NET</td>\n",
              "      <td>49494.0</td>\n",
              "      <td>172810</td>\n",
              "      <td>.AP.S.</td>\n",
              "      <td>normal</td>\n",
              "      <td>465700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153023</th>\n",
              "      <td>67601.294</td>\n",
              "      <td>TCP</td>\n",
              "      <td>OPENSTACK_NET</td>\n",
              "      <td>49494</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>8082.0</td>\n",
              "      <td>170412</td>\n",
              "      <td>.APRS.</td>\n",
              "      <td>normal</td>\n",
              "      <td>28500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153024</th>\n",
              "      <td>67601.103</td>\n",
              "      <td>TCP</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>8082</td>\n",
              "      <td>OPENSTACK_NET</td>\n",
              "      <td>49495.0</td>\n",
              "      <td>148533</td>\n",
              "      <td>.AP.S.</td>\n",
              "      <td>normal</td>\n",
              "      <td>394900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153025</th>\n",
              "      <td>67601.103</td>\n",
              "      <td>TCP</td>\n",
              "      <td>OPENSTACK_NET</td>\n",
              "      <td>49495</td>\n",
              "      <td>EXT_SERVER</td>\n",
              "      <td>8082.0</td>\n",
              "      <td>147538</td>\n",
              "      <td>.APRS.</td>\n",
              "      <td>normal</td>\n",
              "      <td>29500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153026 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2001370-b8a7-4d55-bbce-63647d9711a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2001370-b8a7-4d55-bbce-63647d9711a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2001370-b8a7-4d55-bbce-63647d9711a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Duration  Proto    Src IP Addr  ...   Flags       class      Bytes\n",
              "0           0.000  TCP         26913_25  ...  ....S.  suspicious         46\n",
              "1           0.000  TCP       EXT_SERVER  ...  .A.R..  suspicious         40\n",
              "2           0.000  TCP        26914_116  ...  ....S.  suspicious         46\n",
              "3           0.000  TCP       EXT_SERVER  ...  .A.R..  suspicious         40\n",
              "4           0.001  TCP        26915_202  ...  ....S.  suspicious         46\n",
              "...           ...    ...            ...  ...     ...         ...        ...\n",
              "153021  67601.294  TCP    OPENSTACK_NET  ...  .APRS.      normal   12200000\n",
              "153022  67601.294  TCP       EXT_SERVER  ...  .AP.S.      normal  465700000\n",
              "153023  67601.294  TCP    OPENSTACK_NET  ...  .APRS.      normal   28500000\n",
              "153024  67601.103  TCP       EXT_SERVER  ...  .AP.S.      normal  394900000\n",
              "153025  67601.103  TCP    OPENSTACK_NET  ...  .APRS.      normal   29500000\n",
              "\n",
              "[153026 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "9SYHgIeRqTB9",
        "outputId": "be5f60ed-acca-4265-9b9e-38cc11ee92cc"
      },
      "source": [
        "#convert categorical values to int values\n",
        "\n",
        "csvdata = pd.get_dummies(csvdata, columns=['Proto'])\n",
        "\n",
        "csvdata = pd.get_dummies(csvdata, columns=['Flags'])\n",
        "\n",
        "encoder = ce.BinaryEncoder(cols=['Src IP Addr'])\n",
        "csvdata = encoder.fit_transform(csvdata)\n",
        "csvdata\n",
        "\n",
        "encoder = ce.BinaryEncoder(cols=['Dst IP Addr'])\n",
        "csvdata = encoder.fit_transform(csvdata)\n",
        "csvdata\n",
        "\n",
        "encoder = ce.BinaryEncoder(cols=['Duration'])\n",
        "csvdata = encoder.fit_transform(csvdata)\n",
        "csvdata\n",
        "\n",
        "encoder = ce.BinaryEncoder(cols=['Src Pt'])\n",
        "csvdata = encoder.fit_transform(csvdata)\n",
        "csvdata\n",
        "\n",
        "encoder = ce.BinaryEncoder(cols=['Dst Pt'])\n",
        "csvdata = encoder.fit_transform(csvdata)\n",
        "csvdata\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a0b0a2bf-e6c0-4295-9f9b-e028d94a4e54\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Duration_0</th>\n",
              "      <th>Duration_1</th>\n",
              "      <th>Duration_2</th>\n",
              "      <th>Duration_3</th>\n",
              "      <th>Duration_4</th>\n",
              "      <th>Duration_5</th>\n",
              "      <th>Duration_6</th>\n",
              "      <th>Duration_7</th>\n",
              "      <th>Duration_8</th>\n",
              "      <th>Duration_9</th>\n",
              "      <th>Duration_10</th>\n",
              "      <th>Duration_11</th>\n",
              "      <th>Duration_12</th>\n",
              "      <th>Duration_13</th>\n",
              "      <th>Duration_14</th>\n",
              "      <th>Src IP Addr_0</th>\n",
              "      <th>Src IP Addr_1</th>\n",
              "      <th>Src IP Addr_2</th>\n",
              "      <th>Src IP Addr_3</th>\n",
              "      <th>Src IP Addr_4</th>\n",
              "      <th>Src IP Addr_5</th>\n",
              "      <th>Src IP Addr_6</th>\n",
              "      <th>Src IP Addr_7</th>\n",
              "      <th>Src IP Addr_8</th>\n",
              "      <th>Src IP Addr_9</th>\n",
              "      <th>Src IP Addr_10</th>\n",
              "      <th>Src IP Addr_11</th>\n",
              "      <th>Src IP Addr_12</th>\n",
              "      <th>Src IP Addr_13</th>\n",
              "      <th>Src Pt_0</th>\n",
              "      <th>Src Pt_1</th>\n",
              "      <th>Src Pt_2</th>\n",
              "      <th>Src Pt_3</th>\n",
              "      <th>Src Pt_4</th>\n",
              "      <th>Src Pt_5</th>\n",
              "      <th>Src Pt_6</th>\n",
              "      <th>Src Pt_7</th>\n",
              "      <th>Src Pt_8</th>\n",
              "      <th>Src Pt_9</th>\n",
              "      <th>Src Pt_10</th>\n",
              "      <th>...</th>\n",
              "      <th>Dst Pt_6</th>\n",
              "      <th>Dst Pt_7</th>\n",
              "      <th>Dst Pt_8</th>\n",
              "      <th>Dst Pt_9</th>\n",
              "      <th>Dst Pt_10</th>\n",
              "      <th>Dst Pt_11</th>\n",
              "      <th>Dst Pt_12</th>\n",
              "      <th>Dst Pt_13</th>\n",
              "      <th>Dst Pt_14</th>\n",
              "      <th>Dst Pt_15</th>\n",
              "      <th>Packets</th>\n",
              "      <th>class</th>\n",
              "      <th>Bytes</th>\n",
              "      <th>Proto_GRE</th>\n",
              "      <th>Proto_ICMP</th>\n",
              "      <th>Proto_TCP</th>\n",
              "      <th>Proto_UDP</th>\n",
              "      <th>Flags_  0x52</th>\n",
              "      <th>Flags_  0x5b</th>\n",
              "      <th>Flags_  0xc2</th>\n",
              "      <th>Flags_  0xd3</th>\n",
              "      <th>Flags_  0xd6</th>\n",
              "      <th>Flags_  0xd7</th>\n",
              "      <th>Flags_  0xdb</th>\n",
              "      <th>Flags_  0xdf</th>\n",
              "      <th>Flags_......</th>\n",
              "      <th>Flags_....S.</th>\n",
              "      <th>Flags_...R..</th>\n",
              "      <th>Flags_...RS.</th>\n",
              "      <th>Flags_.A....</th>\n",
              "      <th>Flags_.A..S.</th>\n",
              "      <th>Flags_.A..SF</th>\n",
              "      <th>Flags_.A.R..</th>\n",
              "      <th>Flags_.A.R.F</th>\n",
              "      <th>Flags_.A.RS.</th>\n",
              "      <th>Flags_.A.RSF</th>\n",
              "      <th>Flags_.AP.S.</th>\n",
              "      <th>Flags_.AP.SF</th>\n",
              "      <th>Flags_.APRS.</th>\n",
              "      <th>Flags_.APRSF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153021</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>160681</td>\n",
              "      <td>normal</td>\n",
              "      <td>12200000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153022</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>172810</td>\n",
              "      <td>normal</td>\n",
              "      <td>465700000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153023</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>170412</td>\n",
              "      <td>normal</td>\n",
              "      <td>28500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153024</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>148533</td>\n",
              "      <td>normal</td>\n",
              "      <td>394900000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153025</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>147538</td>\n",
              "      <td>normal</td>\n",
              "      <td>29500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153026 rows × 105 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0b0a2bf-e6c0-4295-9f9b-e028d94a4e54')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0b0a2bf-e6c0-4295-9f9b-e028d94a4e54 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0b0a2bf-e6c0-4295-9f9b-e028d94a4e54');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Duration_0  Duration_1  ...  Flags_.APRS.  Flags_.APRSF\n",
              "0                0           0  ...             0             0\n",
              "1                0           0  ...             0             0\n",
              "2                0           0  ...             0             0\n",
              "3                0           0  ...             0             0\n",
              "4                0           0  ...             0             0\n",
              "...            ...         ...  ...           ...           ...\n",
              "153021           1           0  ...             1             0\n",
              "153022           1           0  ...             0             0\n",
              "153023           1           0  ...             1             0\n",
              "153024           1           0  ...             0             0\n",
              "153025           1           0  ...             1             0\n",
              "\n",
              "[153026 rows x 105 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "2oE7YfjEvrGL",
        "outputId": "7d64e0fa-43a1-4caa-de62-8a3029fa3d7a"
      },
      "source": [
        "#min-max scaling\n",
        "\n",
        "for column in csvdata:\n",
        "  if column.find('_') != -1:\n",
        "    continue\n",
        "  if column.find('class') != -1:\n",
        "    continue\n",
        "  print('-----')\n",
        "  print(column)\n",
        "  min = csvdata[column].min()\n",
        "  max = csvdata[column].max()\n",
        "  print(min)\n",
        "  print(max)\n",
        "  if min != 0:\n",
        "    csvdata[column] = csvdata[column] - min\n",
        "  if max != min:\n",
        "    csvdata[column] = csvdata[column] / (max - min)\n",
        "\n",
        "csvdata"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----\n",
            "Packets\n",
            "1\n",
            "176609\n",
            "-----\n",
            "Bytes\n",
            "28\n",
            "509200000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6cce6192-e6c1-4c9e-b14a-1ed2cba398c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Duration_0</th>\n",
              "      <th>Duration_1</th>\n",
              "      <th>Duration_2</th>\n",
              "      <th>Duration_3</th>\n",
              "      <th>Duration_4</th>\n",
              "      <th>Duration_5</th>\n",
              "      <th>Duration_6</th>\n",
              "      <th>Duration_7</th>\n",
              "      <th>Duration_8</th>\n",
              "      <th>Duration_9</th>\n",
              "      <th>Duration_10</th>\n",
              "      <th>Duration_11</th>\n",
              "      <th>Duration_12</th>\n",
              "      <th>Duration_13</th>\n",
              "      <th>Duration_14</th>\n",
              "      <th>Src IP Addr_0</th>\n",
              "      <th>Src IP Addr_1</th>\n",
              "      <th>Src IP Addr_2</th>\n",
              "      <th>Src IP Addr_3</th>\n",
              "      <th>Src IP Addr_4</th>\n",
              "      <th>Src IP Addr_5</th>\n",
              "      <th>Src IP Addr_6</th>\n",
              "      <th>Src IP Addr_7</th>\n",
              "      <th>Src IP Addr_8</th>\n",
              "      <th>Src IP Addr_9</th>\n",
              "      <th>Src IP Addr_10</th>\n",
              "      <th>Src IP Addr_11</th>\n",
              "      <th>Src IP Addr_12</th>\n",
              "      <th>Src IP Addr_13</th>\n",
              "      <th>Src Pt_0</th>\n",
              "      <th>Src Pt_1</th>\n",
              "      <th>Src Pt_2</th>\n",
              "      <th>Src Pt_3</th>\n",
              "      <th>Src Pt_4</th>\n",
              "      <th>Src Pt_5</th>\n",
              "      <th>Src Pt_6</th>\n",
              "      <th>Src Pt_7</th>\n",
              "      <th>Src Pt_8</th>\n",
              "      <th>Src Pt_9</th>\n",
              "      <th>Src Pt_10</th>\n",
              "      <th>...</th>\n",
              "      <th>Dst Pt_6</th>\n",
              "      <th>Dst Pt_7</th>\n",
              "      <th>Dst Pt_8</th>\n",
              "      <th>Dst Pt_9</th>\n",
              "      <th>Dst Pt_10</th>\n",
              "      <th>Dst Pt_11</th>\n",
              "      <th>Dst Pt_12</th>\n",
              "      <th>Dst Pt_13</th>\n",
              "      <th>Dst Pt_14</th>\n",
              "      <th>Dst Pt_15</th>\n",
              "      <th>Packets</th>\n",
              "      <th>class</th>\n",
              "      <th>Bytes</th>\n",
              "      <th>Proto_GRE</th>\n",
              "      <th>Proto_ICMP</th>\n",
              "      <th>Proto_TCP</th>\n",
              "      <th>Proto_UDP</th>\n",
              "      <th>Flags_  0x52</th>\n",
              "      <th>Flags_  0x5b</th>\n",
              "      <th>Flags_  0xc2</th>\n",
              "      <th>Flags_  0xd3</th>\n",
              "      <th>Flags_  0xd6</th>\n",
              "      <th>Flags_  0xd7</th>\n",
              "      <th>Flags_  0xdb</th>\n",
              "      <th>Flags_  0xdf</th>\n",
              "      <th>Flags_......</th>\n",
              "      <th>Flags_....S.</th>\n",
              "      <th>Flags_...R..</th>\n",
              "      <th>Flags_...RS.</th>\n",
              "      <th>Flags_.A....</th>\n",
              "      <th>Flags_.A..S.</th>\n",
              "      <th>Flags_.A..SF</th>\n",
              "      <th>Flags_.A.R..</th>\n",
              "      <th>Flags_.A.R.F</th>\n",
              "      <th>Flags_.A.RS.</th>\n",
              "      <th>Flags_.A.RSF</th>\n",
              "      <th>Flags_.AP.S.</th>\n",
              "      <th>Flags_.AP.SF</th>\n",
              "      <th>Flags_.APRS.</th>\n",
              "      <th>Flags_.APRSF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>3.534957e-08</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>2.356638e-08</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>3.534957e-08</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>2.356638e-08</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>suspicious</td>\n",
              "      <td>3.534957e-08</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153021</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.909812</td>\n",
              "      <td>normal</td>\n",
              "      <td>2.395910e-02</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153022</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.978489</td>\n",
              "      <td>normal</td>\n",
              "      <td>9.145719e-01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153023</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.964911</td>\n",
              "      <td>normal</td>\n",
              "      <td>5.597010e-02</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153024</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.841026</td>\n",
              "      <td>normal</td>\n",
              "      <td>7.755302e-01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153025</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.835393</td>\n",
              "      <td>normal</td>\n",
              "      <td>5.793396e-02</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153026 rows × 105 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cce6192-e6c1-4c9e-b14a-1ed2cba398c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6cce6192-e6c1-4c9e-b14a-1ed2cba398c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6cce6192-e6c1-4c9e-b14a-1ed2cba398c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Duration_0  Duration_1  ...  Flags_.APRS.  Flags_.APRSF\n",
              "0                0           0  ...             0             0\n",
              "1                0           0  ...             0             0\n",
              "2                0           0  ...             0             0\n",
              "3                0           0  ...             0             0\n",
              "4                0           0  ...             0             0\n",
              "...            ...         ...  ...           ...           ...\n",
              "153021           1           0  ...             1             0\n",
              "153022           1           0  ...             0             0\n",
              "153023           1           0  ...             1             0\n",
              "153024           1           0  ...             0             0\n",
              "153025           1           0  ...             1             0\n",
              "\n",
              "[153026 rows x 105 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cgf_-Y8V-h3l",
        "outputId": "3d23b474-edb6-4014-e7e4-749638a36448"
      },
      "source": [
        "for column in csvdata:\n",
        "  print(csvdata[column].value_counts())\n",
        "  print()\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    152575\n",
            "1       451\n",
            "Name: Duration_0, dtype: int64\n",
            "\n",
            "\n",
            "0    99037\n",
            "1    53989\n",
            "Name: Duration_1, dtype: int64\n",
            "\n",
            "\n",
            "0    111863\n",
            "1     41163\n",
            "Name: Duration_2, dtype: int64\n",
            "\n",
            "\n",
            "0    111358\n",
            "1     41668\n",
            "Name: Duration_3, dtype: int64\n",
            "\n",
            "\n",
            "0    97378\n",
            "1    55648\n",
            "Name: Duration_4, dtype: int64\n",
            "\n",
            "\n",
            "0    84536\n",
            "1    68490\n",
            "Name: Duration_5, dtype: int64\n",
            "\n",
            "\n",
            "1    76962\n",
            "0    76064\n",
            "Name: Duration_6, dtype: int64\n",
            "\n",
            "\n",
            "0    79714\n",
            "1    73312\n",
            "Name: Duration_7, dtype: int64\n",
            "\n",
            "\n",
            "0    88779\n",
            "1    64247\n",
            "Name: Duration_8, dtype: int64\n",
            "\n",
            "\n",
            "0    100231\n",
            "1     52795\n",
            "Name: Duration_9, dtype: int64\n",
            "\n",
            "\n",
            "0    101291\n",
            "1     51735\n",
            "Name: Duration_10, dtype: int64\n",
            "\n",
            "\n",
            "0    84255\n",
            "1    68771\n",
            "Name: Duration_11, dtype: int64\n",
            "\n",
            "\n",
            "0    89880\n",
            "1    63146\n",
            "Name: Duration_12, dtype: int64\n",
            "\n",
            "\n",
            "0    94904\n",
            "1    58122\n",
            "Name: Duration_13, dtype: int64\n",
            "\n",
            "\n",
            "1    86619\n",
            "0    66407\n",
            "Name: Duration_14, dtype: int64\n",
            "\n",
            "\n",
            "0    152757\n",
            "1       269\n",
            "Name: Src IP Addr_0, dtype: int64\n",
            "\n",
            "\n",
            "0    114802\n",
            "1     38224\n",
            "Name: Src IP Addr_1, dtype: int64\n",
            "\n",
            "\n",
            "0    119837\n",
            "1     33189\n",
            "Name: Src IP Addr_2, dtype: int64\n",
            "\n",
            "\n",
            "0    134871\n",
            "1     18155\n",
            "Name: Src IP Addr_3, dtype: int64\n",
            "\n",
            "\n",
            "0    109639\n",
            "1     43387\n",
            "Name: Src IP Addr_4, dtype: int64\n",
            "\n",
            "\n",
            "0    108388\n",
            "1     44638\n",
            "Name: Src IP Addr_5, dtype: int64\n",
            "\n",
            "\n",
            "0    127158\n",
            "1     25868\n",
            "Name: Src IP Addr_6, dtype: int64\n",
            "\n",
            "\n",
            "0    119798\n",
            "1     33228\n",
            "Name: Src IP Addr_7, dtype: int64\n",
            "\n",
            "\n",
            "0    115710\n",
            "1     37316\n",
            "Name: Src IP Addr_8, dtype: int64\n",
            "\n",
            "\n",
            "0    120267\n",
            "1     32759\n",
            "Name: Src IP Addr_9, dtype: int64\n",
            "\n",
            "\n",
            "0    110404\n",
            "1     42622\n",
            "Name: Src IP Addr_10, dtype: int64\n",
            "\n",
            "\n",
            "0    122604\n",
            "1     30422\n",
            "Name: Src IP Addr_11, dtype: int64\n",
            "\n",
            "\n",
            "1    126443\n",
            "0     26583\n",
            "Name: Src IP Addr_12, dtype: int64\n",
            "\n",
            "\n",
            "0    101405\n",
            "1     51621\n",
            "Name: Src IP Addr_13, dtype: int64\n",
            "\n",
            "\n",
            "0    145776\n",
            "1      7250\n",
            "Name: Src Pt_0, dtype: int64\n",
            "\n",
            "\n",
            "0    118284\n",
            "1     34742\n",
            "Name: Src Pt_1, dtype: int64\n",
            "\n",
            "\n",
            "0    118348\n",
            "1     34678\n",
            "Name: Src Pt_2, dtype: int64\n",
            "\n",
            "\n",
            "0    117481\n",
            "1     35545\n",
            "Name: Src Pt_3, dtype: int64\n",
            "\n",
            "\n",
            "0    113388\n",
            "1     39638\n",
            "Name: Src Pt_4, dtype: int64\n",
            "\n",
            "\n",
            "0    109305\n",
            "1     43721\n",
            "Name: Src Pt_5, dtype: int64\n",
            "\n",
            "\n",
            "0    112071\n",
            "1     40955\n",
            "Name: Src Pt_6, dtype: int64\n",
            "\n",
            "\n",
            "0    111956\n",
            "1     41070\n",
            "Name: Src Pt_7, dtype: int64\n",
            "\n",
            "\n",
            "0    109959\n",
            "1     43067\n",
            "Name: Src Pt_8, dtype: int64\n",
            "\n",
            "\n",
            "0    105851\n",
            "1     47175\n",
            "Name: Src Pt_9, dtype: int64\n",
            "\n",
            "\n",
            "1    102371\n",
            "0     50655\n",
            "Name: Src Pt_10, dtype: int64\n",
            "\n",
            "\n",
            "0    107565\n",
            "1     45461\n",
            "Name: Src Pt_11, dtype: int64\n",
            "\n",
            "\n",
            "1    101515\n",
            "0     51511\n",
            "Name: Src Pt_12, dtype: int64\n",
            "\n",
            "\n",
            "1    84012\n",
            "0    69014\n",
            "Name: Src Pt_13, dtype: int64\n",
            "\n",
            "\n",
            "1    104018\n",
            "0     49008\n",
            "Name: Src Pt_14, dtype: int64\n",
            "\n",
            "\n",
            "0    104468\n",
            "1     48558\n",
            "Name: Src Pt_15, dtype: int64\n",
            "\n",
            "\n",
            "0    152802\n",
            "1       224\n",
            "Name: Dst IP Addr_0, dtype: int64\n",
            "\n",
            "\n",
            "0    118319\n",
            "1     34707\n",
            "Name: Dst IP Addr_1, dtype: int64\n",
            "\n",
            "\n",
            "0    119915\n",
            "1     33111\n",
            "Name: Dst IP Addr_2, dtype: int64\n",
            "\n",
            "\n",
            "0    135067\n",
            "1     17959\n",
            "Name: Dst IP Addr_3, dtype: int64\n",
            "\n",
            "\n",
            "0    109730\n",
            "1     43296\n",
            "Name: Dst IP Addr_4, dtype: int64\n",
            "\n",
            "\n",
            "0    124976\n",
            "1     28050\n",
            "Name: Dst IP Addr_5, dtype: int64\n",
            "\n",
            "\n",
            "0    115836\n",
            "1     37190\n",
            "Name: Dst IP Addr_6, dtype: int64\n",
            "\n",
            "\n",
            "0    109137\n",
            "1     43889\n",
            "Name: Dst IP Addr_7, dtype: int64\n",
            "\n",
            "\n",
            "0    105456\n",
            "1     47570\n",
            "Name: Dst IP Addr_8, dtype: int64\n",
            "\n",
            "\n",
            "0    133450\n",
            "1     19576\n",
            "Name: Dst IP Addr_9, dtype: int64\n",
            "\n",
            "\n",
            "0    114307\n",
            "1     38719\n",
            "Name: Dst IP Addr_10, dtype: int64\n",
            "\n",
            "\n",
            "0    120946\n",
            "1     32080\n",
            "Name: Dst IP Addr_11, dtype: int64\n",
            "\n",
            "\n",
            "0    124002\n",
            "1     29024\n",
            "Name: Dst IP Addr_12, dtype: int64\n",
            "\n",
            "\n",
            "1    104251\n",
            "0     48775\n",
            "Name: Dst IP Addr_13, dtype: int64\n",
            "\n",
            "\n",
            "0    145722\n",
            "1      7304\n",
            "Name: Dst Pt_0, dtype: int64\n",
            "\n",
            "\n",
            "0    119385\n",
            "1     33641\n",
            "Name: Dst Pt_1, dtype: int64\n",
            "\n",
            "\n",
            "0    118656\n",
            "1     34370\n",
            "Name: Dst Pt_2, dtype: int64\n",
            "\n",
            "\n",
            "0    116834\n",
            "1     36192\n",
            "Name: Dst Pt_3, dtype: int64\n",
            "\n",
            "\n",
            "0    113319\n",
            "1     39707\n",
            "Name: Dst Pt_4, dtype: int64\n",
            "\n",
            "\n",
            "0    111586\n",
            "1     41440\n",
            "Name: Dst Pt_5, dtype: int64\n",
            "\n",
            "\n",
            "0    111370\n",
            "1     41656\n",
            "Name: Dst Pt_6, dtype: int64\n",
            "\n",
            "\n",
            "0    109651\n",
            "1     43375\n",
            "Name: Dst Pt_7, dtype: int64\n",
            "\n",
            "\n",
            "0    108958\n",
            "1     44068\n",
            "Name: Dst Pt_8, dtype: int64\n",
            "\n",
            "\n",
            "0    107261\n",
            "1     45765\n",
            "Name: Dst Pt_9, dtype: int64\n",
            "\n",
            "\n",
            "1    101652\n",
            "0     51374\n",
            "Name: Dst Pt_10, dtype: int64\n",
            "\n",
            "\n",
            "0    106211\n",
            "1     46815\n",
            "Name: Dst Pt_11, dtype: int64\n",
            "\n",
            "\n",
            "1    100475\n",
            "0     52551\n",
            "Name: Dst Pt_12, dtype: int64\n",
            "\n",
            "\n",
            "1    85399\n",
            "0    67627\n",
            "Name: Dst Pt_13, dtype: int64\n",
            "\n",
            "\n",
            "1    80945\n",
            "0    72081\n",
            "Name: Dst Pt_14, dtype: int64\n",
            "\n",
            "\n",
            "0    89010\n",
            "1    64016\n",
            "Name: Dst Pt_15, dtype: int64\n",
            "\n",
            "\n",
            "0.000000    31259\n",
            "0.000011    12299\n",
            "0.000102    11574\n",
            "0.000091     9824\n",
            "0.000040     6137\n",
            "            ...  \n",
            "0.070042        1\n",
            "0.226309        1\n",
            "0.138856        1\n",
            "0.253046        1\n",
            "0.835393        1\n",
            "Name: Packets, Length: 209, dtype: int64\n",
            "\n",
            "\n",
            "suspicious    97852\n",
            "unknown       33837\n",
            "attacker       9255\n",
            "normal         6180\n",
            "victim         5902\n",
            "Name: class, dtype: int64\n",
            "\n",
            "\n",
            "3.534957e-08    15584\n",
            "2.356638e-08    11084\n",
            "6.199922e-06     9153\n",
            "8.876670e-07     5510\n",
            "2.985075e-07     5211\n",
            "                ...  \n",
            "5.561666e-06        1\n",
            "2.301453e-04        1\n",
            "4.561096e-04        1\n",
            "1.463669e-05        1\n",
            "5.793396e-02        1\n",
            "Name: Bytes, Length: 6789, dtype: int64\n",
            "\n",
            "\n",
            "0    152992\n",
            "1        34\n",
            "Name: Proto_GRE  , dtype: int64\n",
            "\n",
            "\n",
            "0    151373\n",
            "1      1653\n",
            "Name: Proto_ICMP , dtype: int64\n",
            "\n",
            "\n",
            "1    145711\n",
            "0      7315\n",
            "Name: Proto_TCP  , dtype: int64\n",
            "\n",
            "\n",
            "0    147398\n",
            "1      5628\n",
            "Name: Proto_UDP  , dtype: int64\n",
            "\n",
            "\n",
            "0    153024\n",
            "1         2\n",
            "Name: Flags_  0x52, dtype: int64\n",
            "\n",
            "\n",
            "0    153025\n",
            "1         1\n",
            "Name: Flags_  0x5b, dtype: int64\n",
            "\n",
            "\n",
            "0    152903\n",
            "1       123\n",
            "Name: Flags_  0xc2, dtype: int64\n",
            "\n",
            "\n",
            "0    153025\n",
            "1         1\n",
            "Name: Flags_  0xd3, dtype: int64\n",
            "\n",
            "\n",
            "0    153023\n",
            "1         3\n",
            "Name: Flags_  0xd6, dtype: int64\n",
            "\n",
            "\n",
            "0    153004\n",
            "1        22\n",
            "Name: Flags_  0xd7, dtype: int64\n",
            "\n",
            "\n",
            "0    138785\n",
            "1     14241\n",
            "Name: Flags_  0xdb, dtype: int64\n",
            "\n",
            "\n",
            "0    153011\n",
            "1        15\n",
            "Name: Flags_  0xdf, dtype: int64\n",
            "\n",
            "\n",
            "0    145710\n",
            "1      7316\n",
            "Name: Flags_......, dtype: int64\n",
            "\n",
            "\n",
            "0    131710\n",
            "1     21316\n",
            "Name: Flags_....S., dtype: int64\n",
            "\n",
            "\n",
            "0    152747\n",
            "1       279\n",
            "Name: Flags_...R.., dtype: int64\n",
            "\n",
            "\n",
            "0    150385\n",
            "1      2641\n",
            "Name: Flags_...RS., dtype: int64\n",
            "\n",
            "\n",
            "0    152979\n",
            "1        47\n",
            "Name: Flags_.A...., dtype: int64\n",
            "\n",
            "\n",
            "0    143186\n",
            "1      9840\n",
            "Name: Flags_.A..S., dtype: int64\n",
            "\n",
            "\n",
            "0    152892\n",
            "1       134\n",
            "Name: Flags_.A..SF, dtype: int64\n",
            "\n",
            "\n",
            "0    138567\n",
            "1     14459\n",
            "Name: Flags_.A.R.., dtype: int64\n",
            "\n",
            "\n",
            "0    153002\n",
            "1        24\n",
            "Name: Flags_.A.R.F, dtype: int64\n",
            "\n",
            "\n",
            "0    152992\n",
            "1        34\n",
            "Name: Flags_.A.RS., dtype: int64\n",
            "\n",
            "\n",
            "0    152944\n",
            "1        82\n",
            "Name: Flags_.A.RSF, dtype: int64\n",
            "\n",
            "\n",
            "0    152522\n",
            "1       504\n",
            "Name: Flags_.AP.S., dtype: int64\n",
            "\n",
            "\n",
            "0    79714\n",
            "1    73312\n",
            "Name: Flags_.AP.SF, dtype: int64\n",
            "\n",
            "\n",
            "0    152920\n",
            "1       106\n",
            "Name: Flags_.APRS., dtype: int64\n",
            "\n",
            "\n",
            "0    144502\n",
            "1      8524\n",
            "Name: Flags_.APRSF, dtype: int64\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6onvPxwxUNI",
        "outputId": "7ca27dec-941d-46df-d66e-5095c9ea1708"
      },
      "source": [
        "csvdata.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 153026 entries, 0 to 153025\n",
            "Columns: 105 entries, Duration_0 to Flags_.APRSF\n",
            "dtypes: float64(2), int64(75), object(1), uint8(27)\n",
            "memory usage: 95.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "normal = csvdata.query('`class`==\"normal\"')\n",
        "del normal['class']\n",
        "\n",
        "attacker = csvdata.query('`class`==\"attacker\"')\n",
        "del attacker['class']\n",
        "\n",
        "victim = csvdata.query('`class`==\"victim\"')\n",
        "del victim['class']\n",
        "\n",
        "unknown = csvdata.query('`class`==\"unknown\"')\n",
        "del unknown['class']\n",
        "\n",
        "suspicious = csvdata.query('`class`==\"suspicious\"')\n",
        "del suspicious['class']\n",
        "\n",
        "print(\"Normal len: \", len(normal))\n",
        "print(\"Victim len: \", len(victim))\n",
        "print(\"Attacker len: \", len(attacker))\n",
        "print(\"Unknown len: \", len(unknown))\n",
        "print(\"Suspicious len: \", len(suspicious))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbCEy_7-wlAe",
        "outputId": "d3a0003a-5d0c-4665-c5da-0c4fab3067e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal len:  6180\n",
            "Victim len:  5902\n",
            "Attacker len:  9255\n",
            "Unknown len:  33837\n",
            "Suspicious len:  97852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Autoencoder network"
      ],
      "metadata": {
        "id": "mLPOYK-J3D4m"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0cFzZapbzxP"
      },
      "source": [
        "class AE(nn.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.e1 = nn.Linear(in_features=kwargs[\"input_shape\"], out_features=165 ) # 1st Hidden Layer    \n",
        "        self.output_layer = nn.Linear(in_features=165, out_features=kwargs[\"input_shape\"])\n",
        "\n",
        "    def forward(self, features):\n",
        "        out = torch.relu(self.e1(features))\n",
        "        out = self.output_layer(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data loader functions"
      ],
      "metadata": {
        "id": "DLp4Iu_w3NxV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfD1XjtceB9c"
      },
      "source": [
        "class Loader(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        super(Loader, self).__init__()\n",
        "        self.dataset = data\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataset.iloc[idx]\n",
        "        data = torch.from_numpy(np.array(row)).float()\n",
        "        return data\n",
        "\n",
        "class Data_Loader(Loader):\n",
        "    def __init__(self, csvfile):\n",
        "        super(Data_Loader, self).__init__()\n",
        "        self.dataset = pd.read_csv(\n",
        "                       csvfile,\n",
        "                       index_col=False\n",
        "                       )        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training and testing functions"
      ],
      "metadata": {
        "id": "v40Ki7Bd3a-O"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBpZaHhD_y67"
      },
      "source": [
        "def train_epoch(model,device,dataloader,loss_fn,optimizer):\n",
        "    train_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for data in dataloader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, data)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    return train_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fSltl17BAOP"
      },
      "source": [
        "def valid_epoch(model,device,dataloader,loss_fn):\n",
        "    valid_loss = 0.0\n",
        "    model.eval()\n",
        "    for data in dataloader:\n",
        "\n",
        "        data = data.to(device)\n",
        "        output = model(data)\n",
        "        loss=loss_fn(output, data)\n",
        "        valid_loss += loss.item()\n",
        "\n",
        "    return valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLxngo7SBp8i"
      },
      "source": [
        "batch_size = 1\n",
        "num_epochs = 30\n",
        "size = csvdata.shape[1] - 1\n",
        "criterion = nn.MSELoss()\n",
        "k=10\n",
        "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
        "\n",
        "normal_foldperf={}\n",
        "victim_foldperf={}\n",
        "attacker_foldperf={}\n",
        "unknown_foldperf={}\n",
        "suspicious_foldperf={}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "normal_model = AE(input_shape=size)\n",
        "attacker_model = AE(input_shape=size)\n",
        "victim_model = AE(input_shape=size)\n",
        "unknown_model = AE(input_shape=size)\n",
        "suspicious_model = AE(input_shape=size)\n",
        "\n",
        "normal_model.to(device)\n",
        "attacker_model.to(device)\n",
        "victim_model.to(device)\n",
        "unknown_model.to(device)\n",
        "suspicious_model.to(device)\n",
        "\n",
        "normal_optimizer = optim.RMSprop(normal_model.parameters(), lr=0.0001385450437405928)\n",
        "attacker_optimizer = optim.RMSprop(attacker_model.parameters(), lr=0.0001385450437405928)\n",
        "victim_optimizer = optim.RMSprop(victim_model.parameters(), lr=0.0001385450437405928)\n",
        "unknown_optimizer = optim.RMSprop(unknown_model.parameters(), lr=0.0001385450437405928)\n",
        "suspicious_optimizer = optim.RMSprop(suspicious_model.parameters(), lr=0.0001385450437405928)\n",
        "\n",
        "normal_metrics = defaultdict(list)\n",
        "attacker_metrics = defaultdict(list)\n",
        "victim_metrics = defaultdict(list)\n",
        "unknown_metrics = defaultdict(list)\n",
        "suspicious_metrics = defaultdict(list)\n",
        "\n",
        "# normal_history = {'train_loss': [], 'test_loss': []}\n",
        "# attacker_history = {'train_loss': [], 'test_loss': []}\n",
        "# victim_history = {'train_loss': [], 'test_loss': []}\n",
        "# unknown_history = {'train_loss': [], 'test_loss': []}\n",
        "# suspicious_history = {'train_loss': [], 'test_loss': []}\n",
        "\n",
        "save_dir = '/content/ckpts/'\n",
        "if not os.path.exists(save_dir):\n",
        "  os.makedirs(save_dir)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainClassifier(className, data, model, optimizer, metrics, foldperf):\n",
        "  for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(data)))):\n",
        "\n",
        "      print('Fold {}'.format(fold))\n",
        "\n",
        "      train_sampler = SubsetRandomSampler(train_idx)\n",
        "    \n",
        "      test_sampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "      dataset = Loader(data)\n",
        "      train_loader = torch.utils.data.DataLoader(\n",
        "              dataset,\n",
        "              batch_size=batch_size,\n",
        "              sampler=train_sampler\n",
        "          )\n",
        "      test_loader = torch.utils.data.DataLoader(\n",
        "              dataset,\n",
        "              batch_size=batch_size,\n",
        "              sampler=test_sampler\n",
        "          )\n",
        "      \n",
        "\n",
        "      history = {'train_loss': [], 'test_loss': []}\n",
        "\n",
        "      for epoch in range(num_epochs):\n",
        "\n",
        "          train_loss = train_epoch(model,device,train_loader,criterion,optimizer)\n",
        "          test_loss = valid_epoch(model,device,test_loader,criterion)\n",
        "\n",
        "          train_loss = train_loss / len(train_loader.sampler)\n",
        "          test_loss = test_loss / len(test_loader.sampler)\n",
        "\n",
        "          print(\"Epoch:{}/{} AVG Training Loss:{} AVG Test Loss:{} \".format(epoch + 1, num_epochs, train_loss, test_loss))\n",
        "\n",
        "          metrics['train_loss'].append(train_loss)\n",
        "          metrics['val_loss'].append(test_loss)\n",
        "\n",
        "          history['train_loss'].append(train_loss)\n",
        "          history['test_loss'].append(test_loss)\n",
        "      \n",
        "\n",
        "          # !rsync -a /content/ckpts/ /content/drive/\"My Drive\"/AE/e3-kfold-new/\n",
        "\n",
        "\n",
        "      foldperf['fold{}'.format(fold)] = history\n",
        "      torch.save(model.state_dict(), os.path.join(save_dir, '{}_cross_fold_{}.pth'.format(className, fold))) \n",
        "\n",
        "  # torch.save(model,'cross_victim.pt')\n",
        "  torch.save(model.state_dict(), os.path.join(save_dir, '{}_cross.pth'.format(className)))\n",
        "  !rsync -a /content/ckpts/ /content/drive/\"My Drive\"/AE/e3-kfold-new/"
      ],
      "metadata": {
        "id": "M9-Q0eXDjMzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainClassifier(\"Normal\", normal, normal_model, normal_optimizer, normal_metrics, normal_foldperf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w0v3nKVTUpE",
        "outputId": "69104fe4-a654-4209-b1b1-add881803ffe"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0\n",
            "Epoch:1/30 AVG Training Loss:0.05946764146359232 AVG Test Loss:0.037974203972923525 \n",
            "Epoch:2/30 AVG Training Loss:0.025248133374966817 AVG Test Loss:0.015290094719608962 \n",
            "Epoch:3/30 AVG Training Loss:0.008866374185228442 AVG Test Loss:0.004546268076996069 \n",
            "Epoch:4/30 AVG Training Loss:0.002443208238407787 AVG Test Loss:0.0012789769651512179 \n",
            "Epoch:5/30 AVG Training Loss:0.0007394701295322521 AVG Test Loss:0.0005339041892223438 \n",
            "Epoch:6/30 AVG Training Loss:0.0003135661436167167 AVG Test Loss:0.00028064447195693196 \n",
            "Epoch:7/30 AVG Training Loss:0.00016801097568641218 AVG Test Loss:0.0001853000364895459 \n",
            "Epoch:8/30 AVG Training Loss:0.00010393807257271392 AVG Test Loss:0.00013192692875053902 \n",
            "Epoch:9/30 AVG Training Loss:7.104839396749602e-05 AVG Test Loss:0.00010151655649305209 \n",
            "Epoch:10/30 AVG Training Loss:5.138865845865632e-05 AVG Test Loss:8.794583272850437e-05 \n",
            "Epoch:11/30 AVG Training Loss:3.9597083569496694e-05 AVG Test Loss:7.327248004684764e-05 \n",
            "Epoch:12/30 AVG Training Loss:3.175680995319604e-05 AVG Test Loss:6.668878194025447e-05 \n",
            "Epoch:13/30 AVG Training Loss:2.8318933770722344e-05 AVG Test Loss:6.332398954710344e-05 \n",
            "Epoch:14/30 AVG Training Loss:2.474635594551562e-05 AVG Test Loss:5.304763341865452e-05 \n",
            "Epoch:15/30 AVG Training Loss:2.2408961875861922e-05 AVG Test Loss:5.242124451625325e-05 \n",
            "Epoch:16/30 AVG Training Loss:1.887399867516873e-05 AVG Test Loss:5.4094285380800115e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.4504621750367485e-05 AVG Test Loss:4.35706315876491e-05 \n",
            "Epoch:18/30 AVG Training Loss:1.1859764755498047e-05 AVG Test Loss:3.7311926209185176e-05 \n",
            "Epoch:19/30 AVG Training Loss:1.2003560515743744e-05 AVG Test Loss:2.751806846976763e-05 \n",
            "Epoch:20/30 AVG Training Loss:8.466615332511056e-06 AVG Test Loss:2.643221287455222e-05 \n",
            "Epoch:21/30 AVG Training Loss:6.69548847134786e-06 AVG Test Loss:2.555167246399563e-05 \n",
            "Epoch:22/30 AVG Training Loss:7.5111136421574915e-06 AVG Test Loss:2.8783516579132262e-05 \n",
            "Epoch:23/30 AVG Training Loss:6.457864422446171e-06 AVG Test Loss:2.4082965715776377e-05 \n",
            "Epoch:24/30 AVG Training Loss:5.350347283101568e-06 AVG Test Loss:1.9617850023429027e-05 \n",
            "Epoch:25/30 AVG Training Loss:5.046270195650603e-06 AVG Test Loss:2.2286688073738316e-05 \n",
            "Epoch:26/30 AVG Training Loss:4.424235190685853e-06 AVG Test Loss:1.832149405160854e-05 \n",
            "Epoch:27/30 AVG Training Loss:4.223529756055147e-06 AVG Test Loss:1.592504948016903e-05 \n",
            "Epoch:28/30 AVG Training Loss:3.6929530598677545e-06 AVG Test Loss:1.6005322741399574e-05 \n",
            "Epoch:29/30 AVG Training Loss:3.5739930287562447e-06 AVG Test Loss:1.7221439201137905e-05 \n",
            "Epoch:30/30 AVG Training Loss:3.636493361491266e-06 AVG Test Loss:1.4056307558499678e-05 \n",
            "Fold 1\n",
            "Epoch:1/30 AVG Training Loss:4.503028453070069e-06 AVG Test Loss:1.769163504385947e-07 \n",
            "Epoch:2/30 AVG Training Loss:4.774229902931184e-06 AVG Test Loss:4.5293183781657646e-07 \n",
            "Epoch:3/30 AVG Training Loss:3.652579183153542e-06 AVG Test Loss:1.2669410189508606e-06 \n",
            "Epoch:4/30 AVG Training Loss:3.485631285573022e-06 AVG Test Loss:4.245076154193511e-07 \n",
            "Epoch:5/30 AVG Training Loss:3.2782403595921546e-06 AVG Test Loss:1.5224055799165845e-07 \n",
            "Epoch:6/30 AVG Training Loss:2.920179543059454e-06 AVG Test Loss:3.7364753051826214e-07 \n",
            "Epoch:7/30 AVG Training Loss:2.764484032513943e-06 AVG Test Loss:2.1292135876999668e-07 \n",
            "Epoch:8/30 AVG Training Loss:2.3612917029197667e-06 AVG Test Loss:4.1214662059724686e-07 \n",
            "Epoch:9/30 AVG Training Loss:2.603221886260209e-06 AVG Test Loss:6.571686500255404e-07 \n",
            "Epoch:10/30 AVG Training Loss:2.43887884984913e-06 AVG Test Loss:1.8397186342694694e-07 \n",
            "Epoch:11/30 AVG Training Loss:2.3453986843345775e-06 AVG Test Loss:1.7357160788438415e-07 \n",
            "Epoch:12/30 AVG Training Loss:2.3247424431073634e-06 AVG Test Loss:1.6245026307001477e-07 \n",
            "Epoch:13/30 AVG Training Loss:2.3081482160409566e-06 AVG Test Loss:2.837700579325724e-07 \n",
            "Epoch:14/30 AVG Training Loss:2.2862930025886268e-06 AVG Test Loss:2.2562939022225107e-07 \n",
            "Epoch:15/30 AVG Training Loss:2.2271318573986583e-06 AVG Test Loss:4.5329641639726887e-07 \n",
            "Epoch:16/30 AVG Training Loss:2.2053555397648795e-06 AVG Test Loss:9.61651602458449e-07 \n",
            "Epoch:17/30 AVG Training Loss:2.172311356397036e-06 AVG Test Loss:2.1954500162174397e-07 \n",
            "Epoch:18/30 AVG Training Loss:2.164907214473934e-06 AVG Test Loss:1.8484955959017829e-07 \n",
            "Epoch:19/30 AVG Training Loss:2.1808808697600237e-06 AVG Test Loss:1.9456422410264124e-07 \n",
            "Epoch:20/30 AVG Training Loss:2.2434457535745774e-06 AVG Test Loss:2.896035027652913e-07 \n",
            "Epoch:21/30 AVG Training Loss:2.180203544352708e-06 AVG Test Loss:6.208495116891387e-07 \n",
            "Epoch:22/30 AVG Training Loss:2.160811231356244e-06 AVG Test Loss:3.4309586825320164e-07 \n",
            "Epoch:23/30 AVG Training Loss:2.1020932689019388e-06 AVG Test Loss:1.836119537587154e-07 \n",
            "Epoch:24/30 AVG Training Loss:2.124028889484142e-06 AVG Test Loss:1.8216414931289495e-07 \n",
            "Epoch:25/30 AVG Training Loss:2.0134232786993706e-06 AVG Test Loss:3.072897126085887e-07 \n",
            "Epoch:26/30 AVG Training Loss:2.054971338529432e-06 AVG Test Loss:2.0991975176737954e-07 \n",
            "Epoch:27/30 AVG Training Loss:2.1276275940619064e-06 AVG Test Loss:2.4104343027257244e-07 \n",
            "Epoch:28/30 AVG Training Loss:2.097799168477534e-06 AVG Test Loss:1.6478426766420397e-07 \n",
            "Epoch:29/30 AVG Training Loss:2.1177020402923317e-06 AVG Test Loss:2.377970810526772e-07 \n",
            "Epoch:30/30 AVG Training Loss:2.068909225650672e-06 AVG Test Loss:2.0980951187617975e-07 \n",
            "Fold 2\n",
            "Epoch:1/30 AVG Training Loss:2.1469159554740374e-06 AVG Test Loss:2.3221794154219645e-07 \n",
            "Epoch:2/30 AVG Training Loss:2.0591156138325314e-06 AVG Test Loss:3.385299648099335e-07 \n",
            "Epoch:3/30 AVG Training Loss:2.186313047884211e-06 AVG Test Loss:1.370143563925534e-07 \n",
            "Epoch:4/30 AVG Training Loss:2.0195231365609255e-06 AVG Test Loss:2.3036127448520016e-07 \n",
            "Epoch:5/30 AVG Training Loss:2.0668559741173215e-06 AVG Test Loss:1.5999468047799906e-07 \n",
            "Epoch:6/30 AVG Training Loss:1.9882435940516582e-06 AVG Test Loss:1.389900773112801e-06 \n",
            "Epoch:7/30 AVG Training Loss:2.126370510296833e-06 AVG Test Loss:2.541515522210239e-07 \n",
            "Epoch:8/30 AVG Training Loss:2.0970596776284933e-06 AVG Test Loss:3.521016909009424e-07 \n",
            "Epoch:9/30 AVG Training Loss:2.0500131984373063e-06 AVG Test Loss:2.3651992739759536e-07 \n",
            "Epoch:10/30 AVG Training Loss:1.993265521700621e-06 AVG Test Loss:6.304122130384276e-07 \n",
            "Epoch:11/30 AVG Training Loss:1.9907174646606655e-06 AVG Test Loss:3.2759482468266135e-07 \n",
            "Epoch:12/30 AVG Training Loss:2.0548801378041916e-06 AVG Test Loss:1.0258812316318849e-06 \n",
            "Epoch:13/30 AVG Training Loss:2.093809294748552e-06 AVG Test Loss:2.777058946268277e-07 \n",
            "Epoch:14/30 AVG Training Loss:2.040822058624475e-06 AVG Test Loss:9.211065231328903e-07 \n",
            "Epoch:15/30 AVG Training Loss:2.0257061617743187e-06 AVG Test Loss:7.774902984175962e-07 \n",
            "Epoch:16/30 AVG Training Loss:2.057482997472491e-06 AVG Test Loss:3.6951441321821686e-07 \n",
            "Epoch:17/30 AVG Training Loss:2.022710146917343e-06 AVG Test Loss:1.411590662379981e-06 \n",
            "Epoch:18/30 AVG Training Loss:1.9867252084927923e-06 AVG Test Loss:9.788905229743837e-07 \n",
            "Epoch:19/30 AVG Training Loss:2.0573279912252567e-06 AVG Test Loss:9.40022232317028e-07 \n",
            "Epoch:20/30 AVG Training Loss:2.043239025465236e-06 AVG Test Loss:8.905918036700497e-07 \n",
            "Epoch:21/30 AVG Training Loss:2.0056556014556397e-06 AVG Test Loss:6.774330971287506e-07 \n",
            "Epoch:22/30 AVG Training Loss:2.037457277670783e-06 AVG Test Loss:1.0188583161268124e-06 \n",
            "Epoch:23/30 AVG Training Loss:2.013421219091837e-06 AVG Test Loss:1.2877390291212824e-06 \n",
            "Epoch:24/30 AVG Training Loss:1.9995206218558627e-06 AVG Test Loss:9.005762616828901e-07 \n",
            "Epoch:25/30 AVG Training Loss:2.014375624201805e-06 AVG Test Loss:2.565535217563809e-06 \n",
            "Epoch:26/30 AVG Training Loss:2.0432517876348657e-06 AVG Test Loss:9.864012217057196e-07 \n",
            "Epoch:27/30 AVG Training Loss:2.0021496476439518e-06 AVG Test Loss:1.1727185118499354e-06 \n",
            "Epoch:28/30 AVG Training Loss:2.0050107174755964e-06 AVG Test Loss:3.063530441848738e-06 \n",
            "Epoch:29/30 AVG Training Loss:2.007994840677898e-06 AVG Test Loss:2.0552468533072217e-06 \n",
            "Epoch:30/30 AVG Training Loss:1.9649011353280165e-06 AVG Test Loss:8.748136778842265e-07 \n",
            "Fold 3\n",
            "Epoch:1/30 AVG Training Loss:2.1357637269567143e-06 AVG Test Loss:7.694053987920498e-08 \n",
            "Epoch:2/30 AVG Training Loss:2.056119995968927e-06 AVG Test Loss:8.520054455600756e-08 \n",
            "Epoch:3/30 AVG Training Loss:2.0877302073434654e-06 AVG Test Loss:4.53929425166053e-08 \n",
            "Epoch:4/30 AVG Training Loss:2.114467498959454e-06 AVG Test Loss:7.974467881259754e-08 \n",
            "Epoch:5/30 AVG Training Loss:2.0214280498719372e-06 AVG Test Loss:1.4654356661630293e-07 \n",
            "Epoch:6/30 AVG Training Loss:2.090901352151744e-06 AVG Test Loss:8.024220834280244e-08 \n",
            "Epoch:7/30 AVG Training Loss:2.0377888816436786e-06 AVG Test Loss:1.6533698488742783e-07 \n",
            "Epoch:8/30 AVG Training Loss:2.0297876526553694e-06 AVG Test Loss:1.017667812202361e-07 \n",
            "Epoch:9/30 AVG Training Loss:1.9873338951762106e-06 AVG Test Loss:9.742754713861272e-08 \n",
            "Epoch:10/30 AVG Training Loss:2.013866452942073e-06 AVG Test Loss:1.1556460615841396e-07 \n",
            "Epoch:11/30 AVG Training Loss:2.068854790871491e-06 AVG Test Loss:1.5112638777906623e-07 \n",
            "Epoch:12/30 AVG Training Loss:2.0120567015016753e-06 AVG Test Loss:1.0596195855814789e-07 \n",
            "Epoch:13/30 AVG Training Loss:2.00245848542715e-06 AVG Test Loss:1.1746211842238017e-07 \n",
            "Epoch:14/30 AVG Training Loss:1.9278933380899633e-06 AVG Test Loss:6.316816398708668e-07 \n",
            "Epoch:15/30 AVG Training Loss:1.977547655146546e-06 AVG Test Loss:2.1311658012390072e-07 \n",
            "Epoch:16/30 AVG Training Loss:2.0196542409769826e-06 AVG Test Loss:1.7380852163796695e-07 \n",
            "Epoch:17/30 AVG Training Loss:2.072492264314457e-06 AVG Test Loss:2.9967435379202027e-07 \n",
            "Epoch:18/30 AVG Training Loss:1.9709174476563806e-06 AVG Test Loss:4.772780709408548e-07 \n",
            "Epoch:19/30 AVG Training Loss:1.9922709135584838e-06 AVG Test Loss:3.2718630505566663e-07 \n",
            "Epoch:20/30 AVG Training Loss:2.0018826101625592e-06 AVG Test Loss:2.693395908603602e-07 \n",
            "Epoch:21/30 AVG Training Loss:1.9827208233624157e-06 AVG Test Loss:2.2568003403172928e-07 \n",
            "Epoch:22/30 AVG Training Loss:1.964856447660581e-06 AVG Test Loss:2.1571993750107717e-07 \n",
            "Epoch:23/30 AVG Training Loss:1.956352553926754e-06 AVG Test Loss:1.0911847709356414e-07 \n",
            "Epoch:24/30 AVG Training Loss:1.9701509606374547e-06 AVG Test Loss:1.5945376325220933e-07 \n",
            "Epoch:25/30 AVG Training Loss:1.941815300104965e-06 AVG Test Loss:1.9096354218065523e-07 \n",
            "Epoch:26/30 AVG Training Loss:2.0473731311519443e-06 AVG Test Loss:1.351450667762531e-07 \n",
            "Epoch:27/30 AVG Training Loss:2.0072873439566028e-06 AVG Test Loss:1.163236919309434e-07 \n",
            "Epoch:28/30 AVG Training Loss:1.9109303622946256e-06 AVG Test Loss:1.6329882582966145e-07 \n",
            "Epoch:29/30 AVG Training Loss:1.9538582804812476e-06 AVG Test Loss:1.0310660239083361e-07 \n",
            "Epoch:30/30 AVG Training Loss:2.056719617529941e-06 AVG Test Loss:1.7979083597965028e-07 \n",
            "Fold 4\n",
            "Epoch:1/30 AVG Training Loss:2.596184899302091e-07 AVG Test Loss:1.568598079272989e-05 \n",
            "Epoch:2/30 AVG Training Loss:2.257612781042904e-07 AVG Test Loss:1.5824410503099767e-05 \n",
            "Epoch:3/30 AVG Training Loss:2.111776511256087e-07 AVG Test Loss:1.5717306141296296e-05 \n",
            "Epoch:4/30 AVG Training Loss:2.6473458347223004e-07 AVG Test Loss:1.575267205684965e-05 \n",
            "Epoch:5/30 AVG Training Loss:1.7335276123577216e-07 AVG Test Loss:1.5745176171707606e-05 \n",
            "Epoch:6/30 AVG Training Loss:2.3108544501430473e-07 AVG Test Loss:1.5769733206695165e-05 \n",
            "Epoch:7/30 AVG Training Loss:2.3247744885455466e-07 AVG Test Loss:1.6276287814311417e-05 \n",
            "Epoch:8/30 AVG Training Loss:2.2988463647965033e-07 AVG Test Loss:1.5869829003280966e-05 \n",
            "Epoch:9/30 AVG Training Loss:2.7862164176245767e-07 AVG Test Loss:1.577200222562056e-05 \n",
            "Epoch:10/30 AVG Training Loss:2.3029333569044152e-07 AVG Test Loss:1.60418223616587e-05 \n",
            "Epoch:11/30 AVG Training Loss:1.4500217448778567e-07 AVG Test Loss:1.594801605278853e-05 \n",
            "Epoch:12/30 AVG Training Loss:2.5177482311845185e-07 AVG Test Loss:1.625875423856317e-05 \n",
            "Epoch:13/30 AVG Training Loss:1.9849955311778467e-07 AVG Test Loss:1.5830802107179012e-05 \n",
            "Epoch:14/30 AVG Training Loss:1.869805326598613e-07 AVG Test Loss:1.586855864803038e-05 \n",
            "Epoch:15/30 AVG Training Loss:2.849669711904849e-07 AVG Test Loss:1.598354131230838e-05 \n",
            "Epoch:16/30 AVG Training Loss:2.187135559261019e-07 AVG Test Loss:1.589845491772653e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.4355321716529653e-07 AVG Test Loss:1.6118490905201103e-05 \n",
            "Epoch:18/30 AVG Training Loss:2.7454385188896676e-07 AVG Test Loss:1.5924950824023413e-05 \n",
            "Epoch:19/30 AVG Training Loss:2.723507255486348e-07 AVG Test Loss:1.5936268167562532e-05 \n",
            "Epoch:20/30 AVG Training Loss:1.8500604531745338e-07 AVG Test Loss:1.6010509027439527e-05 \n",
            "Epoch:21/30 AVG Training Loss:2.0347411453880063e-07 AVG Test Loss:1.6031409178412347e-05 \n",
            "Epoch:22/30 AVG Training Loss:2.4235911236434684e-07 AVG Test Loss:1.6406775558326584e-05 \n",
            "Epoch:23/30 AVG Training Loss:2.264783793421875e-07 AVG Test Loss:1.5919355937866855e-05 \n",
            "Epoch:24/30 AVG Training Loss:2.5426193413669754e-07 AVG Test Loss:1.5813426162755962e-05 \n",
            "Epoch:25/30 AVG Training Loss:2.549737896668992e-07 AVG Test Loss:1.6008980976319683e-05 \n",
            "Epoch:26/30 AVG Training Loss:3.1465670326626633e-07 AVG Test Loss:1.6369386020154805e-05 \n",
            "Epoch:27/30 AVG Training Loss:2.662681154292193e-07 AVG Test Loss:1.6055661891400807e-05 \n",
            "Epoch:28/30 AVG Training Loss:2.716129349718489e-07 AVG Test Loss:1.597487708105625e-05 \n",
            "Epoch:29/30 AVG Training Loss:2.090976710827821e-07 AVG Test Loss:1.6047219135601647e-05 \n",
            "Epoch:30/30 AVG Training Loss:3.173847913019613e-07 AVG Test Loss:1.618524069811711e-05 \n",
            "Fold 5\n",
            "Epoch:1/30 AVG Training Loss:2.0002456607237744e-06 AVG Test Loss:8.942712614868348e-08 \n",
            "Epoch:2/30 AVG Training Loss:1.983053158653976e-06 AVG Test Loss:5.27849417560755e-07 \n",
            "Epoch:3/30 AVG Training Loss:2.0723422525955874e-06 AVG Test Loss:1.5808403720225355e-07 \n",
            "Epoch:4/30 AVG Training Loss:1.935764308414545e-06 AVG Test Loss:2.4836947064917736e-07 \n",
            "Epoch:5/30 AVG Training Loss:1.9993135130870274e-06 AVG Test Loss:1.3044066707054472e-07 \n",
            "Epoch:6/30 AVG Training Loss:2.0591000420233335e-06 AVG Test Loss:2.0024307759588335e-07 \n",
            "Epoch:7/30 AVG Training Loss:2.003424531842062e-06 AVG Test Loss:2.438281600115138e-07 \n",
            "Epoch:8/30 AVG Training Loss:1.9529704213624576e-06 AVG Test Loss:5.708970938937935e-07 \n",
            "Epoch:9/30 AVG Training Loss:1.9689962751888145e-06 AVG Test Loss:2.1479449677098883e-07 \n",
            "Epoch:10/30 AVG Training Loss:1.9888714365343248e-06 AVG Test Loss:2.1524870261153818e-07 \n",
            "Epoch:11/30 AVG Training Loss:1.8938684545553405e-06 AVG Test Loss:4.1512380643574955e-07 \n",
            "Epoch:12/30 AVG Training Loss:1.9413609297681435e-06 AVG Test Loss:7.43747112056439e-07 \n",
            "Epoch:13/30 AVG Training Loss:2.0080887853871527e-06 AVG Test Loss:2.8344408374233585e-07 \n",
            "Epoch:14/30 AVG Training Loss:1.9862443412943397e-06 AVG Test Loss:1.6507306082406606e-07 \n",
            "Epoch:15/30 AVG Training Loss:1.9973069893762666e-06 AVG Test Loss:5.345534399121414e-07 \n",
            "Epoch:16/30 AVG Training Loss:1.9568819529168742e-06 AVG Test Loss:2.817407244399836e-07 \n",
            "Epoch:17/30 AVG Training Loss:2.0967632007887612e-06 AVG Test Loss:2.3945778234348976e-07 \n",
            "Epoch:18/30 AVG Training Loss:2.005235225656501e-06 AVG Test Loss:1.5074153463191802e-07 \n",
            "Epoch:19/30 AVG Training Loss:1.9012709330390417e-06 AVG Test Loss:3.438813122164252e-07 \n",
            "Epoch:20/30 AVG Training Loss:1.8779388104976691e-06 AVG Test Loss:2.0840748660755414e-07 \n",
            "Epoch:21/30 AVG Training Loss:1.9479695006588575e-06 AVG Test Loss:1.3124488387365036e-07 \n",
            "Epoch:22/30 AVG Training Loss:1.9865087210578804e-06 AVG Test Loss:2.3186721603605945e-07 \n",
            "Epoch:23/30 AVG Training Loss:1.9626361746281505e-06 AVG Test Loss:2.4143946261132197e-07 \n",
            "Epoch:24/30 AVG Training Loss:1.931730345564074e-06 AVG Test Loss:5.43238745441541e-07 \n",
            "Epoch:25/30 AVG Training Loss:1.98688897170587e-06 AVG Test Loss:2.3499640562707113e-07 \n",
            "Epoch:26/30 AVG Training Loss:2.0233079073046737e-06 AVG Test Loss:9.604979881933063e-07 \n",
            "Epoch:27/30 AVG Training Loss:1.9702481851204155e-06 AVG Test Loss:1.3093243269505271e-07 \n",
            "Epoch:28/30 AVG Training Loss:1.9455652315447085e-06 AVG Test Loss:1.7474694292489843e-07 \n",
            "Epoch:29/30 AVG Training Loss:1.956868508991891e-06 AVG Test Loss:9.702809114882504e-08 \n",
            "Epoch:30/30 AVG Training Loss:1.9840576745966646e-06 AVG Test Loss:4.586917224245352e-07 \n",
            "Fold 6\n",
            "Epoch:1/30 AVG Training Loss:2.0146848530544964e-06 AVG Test Loss:1.7523305347023103e-07 \n",
            "Epoch:2/30 AVG Training Loss:1.9203895807452126e-06 AVG Test Loss:5.77576526277959e-07 \n",
            "Epoch:3/30 AVG Training Loss:1.8866546984821249e-06 AVG Test Loss:2.0559737044597472e-06 \n",
            "Epoch:4/30 AVG Training Loss:2.036983882933829e-06 AVG Test Loss:2.8184007467482484e-07 \n",
            "Epoch:5/30 AVG Training Loss:1.889039351293512e-06 AVG Test Loss:5.522522021177819e-07 \n",
            "Epoch:6/30 AVG Training Loss:1.9390513494224223e-06 AVG Test Loss:1.219520138662494e-07 \n",
            "Epoch:7/30 AVG Training Loss:1.995928635172765e-06 AVG Test Loss:2.2265952038061898e-07 \n",
            "Epoch:8/30 AVG Training Loss:1.8700773464556481e-06 AVG Test Loss:1.4679708419098825e-07 \n",
            "Epoch:9/30 AVG Training Loss:1.9383758945172648e-06 AVG Test Loss:3.355743781541141e-07 \n",
            "Epoch:10/30 AVG Training Loss:1.9928461648162407e-06 AVG Test Loss:3.3165506507602744e-07 \n",
            "Epoch:11/30 AVG Training Loss:1.9191860594920255e-06 AVG Test Loss:2.580196620072933e-07 \n",
            "Epoch:12/30 AVG Training Loss:1.9010080443439081e-06 AVG Test Loss:3.7129635419156794e-07 \n",
            "Epoch:13/30 AVG Training Loss:1.9154743377974918e-06 AVG Test Loss:9.813133878540839e-07 \n",
            "Epoch:14/30 AVG Training Loss:1.9572658851650627e-06 AVG Test Loss:1.3006214525356964e-06 \n",
            "Epoch:15/30 AVG Training Loss:1.927061071117302e-06 AVG Test Loss:4.1945182447595026e-07 \n",
            "Epoch:16/30 AVG Training Loss:2.006198263836435e-06 AVG Test Loss:7.59686523971031e-07 \n",
            "Epoch:17/30 AVG Training Loss:1.9511387752652805e-06 AVG Test Loss:4.5950131348481154e-07 \n",
            "Epoch:18/30 AVG Training Loss:1.95881355125184e-06 AVG Test Loss:5.025317025406128e-07 \n",
            "Epoch:19/30 AVG Training Loss:1.9686587340744147e-06 AVG Test Loss:2.3214277497781602e-07 \n",
            "Epoch:20/30 AVG Training Loss:1.969151602384413e-06 AVG Test Loss:3.4638843288789895e-07 \n",
            "Epoch:21/30 AVG Training Loss:1.981812920709002e-06 AVG Test Loss:4.958622877168137e-07 \n",
            "Epoch:22/30 AVG Training Loss:1.9256179508197826e-06 AVG Test Loss:2.9143529078508073e-07 \n",
            "Epoch:23/30 AVG Training Loss:1.9246591761587044e-06 AVG Test Loss:4.81675363643552e-07 \n",
            "Epoch:24/30 AVG Training Loss:1.9746088404314074e-06 AVG Test Loss:9.605276453366452e-07 \n",
            "Epoch:25/30 AVG Training Loss:1.917548084873537e-06 AVG Test Loss:2.753290802481237e-07 \n",
            "Epoch:26/30 AVG Training Loss:1.9069485860667028e-06 AVG Test Loss:3.2298221276432005e-07 \n",
            "Epoch:27/30 AVG Training Loss:1.9356577979723003e-06 AVG Test Loss:6.025880041152512e-07 \n",
            "Epoch:28/30 AVG Training Loss:1.9242643375695637e-06 AVG Test Loss:7.183024163269784e-07 \n",
            "Epoch:29/30 AVG Training Loss:1.9023344911015377e-06 AVG Test Loss:1.62253039624262e-06 \n",
            "Epoch:30/30 AVG Training Loss:2.0160165106876826e-06 AVG Test Loss:5.12624535366785e-07 \n",
            "Fold 7\n",
            "Epoch:1/30 AVG Training Loss:1.9749486270807792e-06 AVG Test Loss:9.371982660123529e-08 \n",
            "Epoch:2/30 AVG Training Loss:2.037246605589967e-06 AVG Test Loss:9.066045461911627e-08 \n",
            "Epoch:3/30 AVG Training Loss:1.984690225119893e-06 AVG Test Loss:6.921269791242643e-08 \n",
            "Epoch:4/30 AVG Training Loss:1.9147552257476217e-06 AVG Test Loss:2.918987888246045e-07 \n",
            "Epoch:5/30 AVG Training Loss:2.1276030062350015e-06 AVG Test Loss:4.3981954073080694e-08 \n",
            "Epoch:6/30 AVG Training Loss:2.0347513401966765e-06 AVG Test Loss:3.640394602453191e-08 \n",
            "Epoch:7/30 AVG Training Loss:1.9071665265444205e-06 AVG Test Loss:1.3468197992721448e-07 \n",
            "Epoch:8/30 AVG Training Loss:2.0812378670751038e-06 AVG Test Loss:1.0828790626894208e-07 \n",
            "Epoch:9/30 AVG Training Loss:2.0101160202563657e-06 AVG Test Loss:1.8696092584836525e-07 \n",
            "Epoch:10/30 AVG Training Loss:2.0604049087158426e-06 AVG Test Loss:3.887448557109444e-08 \n",
            "Epoch:11/30 AVG Training Loss:1.953428701974467e-06 AVG Test Loss:1.0756775055202239e-07 \n",
            "Epoch:12/30 AVG Training Loss:1.914878571844373e-06 AVG Test Loss:6.073256739118203e-08 \n",
            "Epoch:13/30 AVG Training Loss:2.0023129736365976e-06 AVG Test Loss:1.6407655905748679e-07 \n",
            "Epoch:14/30 AVG Training Loss:1.9502929460978592e-06 AVG Test Loss:1.8880436593629774e-08 \n",
            "Epoch:15/30 AVG Training Loss:1.8731281494984728e-06 AVG Test Loss:2.1523877301754513e-08 \n",
            "Epoch:16/30 AVG Training Loss:2.1719297279262283e-06 AVG Test Loss:6.021421696060599e-08 \n",
            "Epoch:17/30 AVG Training Loss:1.9830243102700335e-06 AVG Test Loss:1.719466194088784e-07 \n",
            "Epoch:18/30 AVG Training Loss:1.928045138671094e-06 AVG Test Loss:2.9276647512830263e-08 \n",
            "Epoch:19/30 AVG Training Loss:1.9928813041026527e-06 AVG Test Loss:9.796755353565902e-08 \n",
            "Epoch:20/30 AVG Training Loss:1.9414585970708247e-06 AVG Test Loss:2.0756268740575818e-07 \n",
            "Epoch:21/30 AVG Training Loss:2.0135657815472984e-06 AVG Test Loss:9.918128704794629e-08 \n",
            "Epoch:22/30 AVG Training Loss:2.035992100136791e-06 AVG Test Loss:1.0106700043676305e-07 \n",
            "Epoch:23/30 AVG Training Loss:1.948594817759712e-06 AVG Test Loss:6.980826590455951e-08 \n",
            "Epoch:24/30 AVG Training Loss:1.9495825407116713e-06 AVG Test Loss:3.6000540668816114e-07 \n",
            "Epoch:25/30 AVG Training Loss:1.9426926468270407e-06 AVG Test Loss:2.2730050375484102e-08 \n",
            "Epoch:26/30 AVG Training Loss:1.9540447905996696e-06 AVG Test Loss:8.148666019304202e-08 \n",
            "Epoch:27/30 AVG Training Loss:2.053675100125007e-06 AVG Test Loss:3.1565641386828545e-07 \n",
            "Epoch:28/30 AVG Training Loss:1.9731913696750746e-06 AVG Test Loss:5.1162517473309935e-08 \n",
            "Epoch:29/30 AVG Training Loss:1.9378371030186346e-06 AVG Test Loss:1.6646647861181551e-07 \n",
            "Epoch:30/30 AVG Training Loss:1.9594868500215405e-06 AVG Test Loss:1.1160365600261951e-07 \n",
            "Fold 8\n",
            "Epoch:1/30 AVG Training Loss:1.9242337083477913e-06 AVG Test Loss:3.7961935420246914e-07 \n",
            "Epoch:2/30 AVG Training Loss:1.9720987244265075e-06 AVG Test Loss:2.0959992515092369e-07 \n",
            "Epoch:3/30 AVG Training Loss:1.8940802540147318e-06 AVG Test Loss:5.846897545540584e-07 \n",
            "Epoch:4/30 AVG Training Loss:1.9435176316222514e-06 AVG Test Loss:2.255618391771997e-07 \n",
            "Epoch:5/30 AVG Training Loss:1.9570332316210247e-06 AVG Test Loss:9.199704686142735e-07 \n",
            "Epoch:6/30 AVG Training Loss:1.926767420510117e-06 AVG Test Loss:1.412017121554073e-07 \n",
            "Epoch:7/30 AVG Training Loss:1.8867095133600824e-06 AVG Test Loss:2.440253811145907e-07 \n",
            "Epoch:8/30 AVG Training Loss:1.9443398360468234e-06 AVG Test Loss:4.567120969974934e-07 \n",
            "Epoch:9/30 AVG Training Loss:1.8946997746727498e-06 AVG Test Loss:3.735582036762898e-07 \n",
            "Epoch:10/30 AVG Training Loss:1.9585104143281074e-06 AVG Test Loss:1.9966534807988992e-07 \n",
            "Epoch:11/30 AVG Training Loss:1.943237072727653e-06 AVG Test Loss:1.2529535263141096e-07 \n",
            "Epoch:12/30 AVG Training Loss:1.8978710861080905e-06 AVG Test Loss:4.4293655438328115e-07 \n",
            "Epoch:13/30 AVG Training Loss:1.9690015424352263e-06 AVG Test Loss:6.328638230875278e-07 \n",
            "Epoch:14/30 AVG Training Loss:1.8566897175383555e-06 AVG Test Loss:4.423791675642248e-07 \n",
            "Epoch:15/30 AVG Training Loss:1.975570791442593e-06 AVG Test Loss:5.066953569448489e-07 \n",
            "Epoch:16/30 AVG Training Loss:1.951851930302169e-06 AVG Test Loss:4.871507661797227e-07 \n",
            "Epoch:17/30 AVG Training Loss:1.9181788804172804e-06 AVG Test Loss:5.513854208279977e-07 \n",
            "Epoch:18/30 AVG Training Loss:1.9064798741062884e-06 AVG Test Loss:2.756972151400897e-07 \n",
            "Epoch:19/30 AVG Training Loss:1.920709867010526e-06 AVG Test Loss:2.592124401950241e-07 \n",
            "Epoch:20/30 AVG Training Loss:1.9273277070578993e-06 AVG Test Loss:3.890916499434844e-07 \n",
            "Epoch:21/30 AVG Training Loss:1.9073204653930338e-06 AVG Test Loss:9.744215157298224e-07 \n",
            "Epoch:22/30 AVG Training Loss:1.9614187539882856e-06 AVG Test Loss:8.186725604882668e-07 \n",
            "Epoch:23/30 AVG Training Loss:1.8782207625578316e-06 AVG Test Loss:7.189262276086787e-07 \n",
            "Epoch:24/30 AVG Training Loss:1.8756572670075335e-06 AVG Test Loss:5.238762165680135e-07 \n",
            "Epoch:25/30 AVG Training Loss:1.916791203053502e-06 AVG Test Loss:3.3300497349364044e-07 \n",
            "Epoch:26/30 AVG Training Loss:1.927670882763722e-06 AVG Test Loss:6.982947684410785e-07 \n",
            "Epoch:27/30 AVG Training Loss:1.8999531697994802e-06 AVG Test Loss:3.880446673823027e-07 \n",
            "Epoch:28/30 AVG Training Loss:1.8867701635238663e-06 AVG Test Loss:5.168411773105558e-07 \n",
            "Epoch:29/30 AVG Training Loss:2.031892790870432e-06 AVG Test Loss:4.4372864450170695e-07 \n",
            "Epoch:30/30 AVG Training Loss:1.92483174661959e-06 AVG Test Loss:3.327520257016105e-07 \n",
            "Fold 9\n",
            "Epoch:1/30 AVG Training Loss:2.0185026844789046e-06 AVG Test Loss:3.063493779283326e-08 \n",
            "Epoch:2/30 AVG Training Loss:2.004556196164909e-06 AVG Test Loss:4.395683773118719e-08 \n",
            "Epoch:3/30 AVG Training Loss:1.92316651691048e-06 AVG Test Loss:6.937320412647476e-08 \n",
            "Epoch:4/30 AVG Training Loss:1.9957473369190066e-06 AVG Test Loss:1.4068856813581736e-07 \n",
            "Epoch:5/30 AVG Training Loss:1.983612315039232e-06 AVG Test Loss:2.9987370890213246e-08 \n",
            "Epoch:6/30 AVG Training Loss:1.9602748875351124e-06 AVG Test Loss:3.0619242416259534e-08 \n",
            "Epoch:7/30 AVG Training Loss:1.959184276138426e-06 AVG Test Loss:6.828530780484723e-08 \n",
            "Epoch:8/30 AVG Training Loss:1.9250383350211826e-06 AVG Test Loss:3.783369589110866e-08 \n",
            "Epoch:9/30 AVG Training Loss:2.006134328748678e-06 AVG Test Loss:2.010683340023038e-07 \n",
            "Epoch:10/30 AVG Training Loss:1.9656925432195745e-06 AVG Test Loss:5.928541158470344e-08 \n",
            "Epoch:11/30 AVG Training Loss:2.0025486345672032e-06 AVG Test Loss:3.7800624019307284e-08 \n",
            "Epoch:12/30 AVG Training Loss:1.8919737302965266e-06 AVG Test Loss:2.8981715009122654e-08 \n",
            "Epoch:13/30 AVG Training Loss:1.919685458443472e-06 AVG Test Loss:7.973171778527973e-08 \n",
            "Epoch:14/30 AVG Training Loss:1.920331967058073e-06 AVG Test Loss:9.731804046728482e-08 \n",
            "Epoch:15/30 AVG Training Loss:1.9904111698822447e-06 AVG Test Loss:4.347128248387495e-08 \n",
            "Epoch:16/30 AVG Training Loss:1.972288223109508e-06 AVG Test Loss:5.306049578464383e-08 \n",
            "Epoch:17/30 AVG Training Loss:1.8653738020585277e-06 AVG Test Loss:7.44159864991599e-08 \n",
            "Epoch:18/30 AVG Training Loss:2.0176726148824852e-06 AVG Test Loss:4.815110154501912e-08 \n",
            "Epoch:19/30 AVG Training Loss:1.944610469015677e-06 AVG Test Loss:8.60577344647634e-08 \n",
            "Epoch:20/30 AVG Training Loss:1.905170758610552e-06 AVG Test Loss:2.9918141570205354e-08 \n",
            "Epoch:21/30 AVG Training Loss:2.0243329365136576e-06 AVG Test Loss:6.063892509835377e-08 \n",
            "Epoch:22/30 AVG Training Loss:1.939773198153187e-06 AVG Test Loss:4.20096738534073e-08 \n",
            "Epoch:23/30 AVG Training Loss:1.9071555249139392e-06 AVG Test Loss:6.913547645119416e-08 \n",
            "Epoch:24/30 AVG Training Loss:1.950189877813326e-06 AVG Test Loss:1.372244561229992e-07 \n",
            "Epoch:25/30 AVG Training Loss:1.929637322319961e-06 AVG Test Loss:2.770965753498279e-07 \n",
            "Epoch:26/30 AVG Training Loss:1.9945569160018265e-06 AVG Test Loss:1.855750335966129e-07 \n",
            "Epoch:27/30 AVG Training Loss:1.9020509865962212e-06 AVG Test Loss:9.800656340083768e-08 \n",
            "Epoch:28/30 AVG Training Loss:1.9905241633039492e-06 AVG Test Loss:6.446194733971334e-08 \n",
            "Epoch:29/30 AVG Training Loss:1.9073139899813044e-06 AVG Test Loss:2.202436281870956e-07 \n",
            "Epoch:30/30 AVG Training Loss:1.9310264492998475e-06 AVG Test Loss:6.993952538055328e-08 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainClassifier(\"Attacker\", attacker, attacker_model, attacker_optimizer, attacker_metrics, attacker_foldperf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH3Sg-fX0Q9_",
        "outputId": "3dbd14ad-80b3-4c24-a476-05d107e1569f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0\n",
            "Epoch:1/30 AVG Training Loss:0.04643849442611321 AVG Test Loss:0.02155913429014932 \n",
            "Epoch:2/30 AVG Training Loss:0.012666557332132266 AVG Test Loss:0.006599255099218262 \n",
            "Epoch:3/30 AVG Training Loss:0.003998324631469696 AVG Test Loss:0.0021356690241872874 \n",
            "Epoch:4/30 AVG Training Loss:0.0013678114856429569 AVG Test Loss:0.0008057103244775948 \n",
            "Epoch:5/30 AVG Training Loss:0.0005336312335075279 AVG Test Loss:0.0003681342913036954 \n",
            "Epoch:6/30 AVG Training Loss:0.0002514949207696424 AVG Test Loss:0.00018266834866902077 \n",
            "Epoch:7/30 AVG Training Loss:0.00014073895414731336 AVG Test Loss:0.00011657261599994465 \n",
            "Epoch:8/30 AVG Training Loss:8.577525386394202e-05 AVG Test Loss:7.82876346964966e-05 \n",
            "Epoch:9/30 AVG Training Loss:5.780152061300683e-05 AVG Test Loss:5.0768019988162844e-05 \n",
            "Epoch:10/30 AVG Training Loss:4.21176090992741e-05 AVG Test Loss:4.1342823981791975e-05 \n",
            "Epoch:11/30 AVG Training Loss:3.496009055835434e-05 AVG Test Loss:3.9039024232311636e-05 \n",
            "Epoch:12/30 AVG Training Loss:2.9600781107891585e-05 AVG Test Loss:3.135878162025165e-05 \n",
            "Epoch:13/30 AVG Training Loss:2.5648860622831266e-05 AVG Test Loss:2.981359826887681e-05 \n",
            "Epoch:14/30 AVG Training Loss:2.274849920931505e-05 AVG Test Loss:2.6415721742961468e-05 \n",
            "Epoch:15/30 AVG Training Loss:2.0831085935813242e-05 AVG Test Loss:2.690263359686647e-05 \n",
            "Epoch:16/30 AVG Training Loss:1.8796058713252238e-05 AVG Test Loss:2.428111956847284e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.755574944877633e-05 AVG Test Loss:2.2037667134734733e-05 \n",
            "Epoch:18/30 AVG Training Loss:1.5705155214234538e-05 AVG Test Loss:2.4035582227744183e-05 \n",
            "Epoch:19/30 AVG Training Loss:1.3711817568588302e-05 AVG Test Loss:2.1405173356017945e-05 \n",
            "Epoch:20/30 AVG Training Loss:1.3005890278480463e-05 AVG Test Loss:2.1244363228234205e-05 \n",
            "Epoch:21/30 AVG Training Loss:1.2589436809937167e-05 AVG Test Loss:2.113658812981406e-05 \n",
            "Epoch:22/30 AVG Training Loss:1.2253928497529114e-05 AVG Test Loss:2.5247076907001066e-05 \n",
            "Epoch:23/30 AVG Training Loss:1.2392567618033054e-05 AVG Test Loss:2.1383703820934637e-05 \n",
            "Epoch:24/30 AVG Training Loss:1.2059739805059672e-05 AVG Test Loss:2.092552628508027e-05 \n",
            "Epoch:25/30 AVG Training Loss:1.2047669323260456e-05 AVG Test Loss:2.0953296427844894e-05 \n",
            "Epoch:26/30 AVG Training Loss:1.2087687927552374e-05 AVG Test Loss:2.3045429476656218e-05 \n",
            "Epoch:27/30 AVG Training Loss:1.184071591072068e-05 AVG Test Loss:2.1435928344844656e-05 \n",
            "Epoch:28/30 AVG Training Loss:1.1930812716098847e-05 AVG Test Loss:2.0931308380669762e-05 \n",
            "Epoch:29/30 AVG Training Loss:1.1813684336422264e-05 AVG Test Loss:2.0945275159660055e-05 \n",
            "Epoch:30/30 AVG Training Loss:1.1607901353079191e-05 AVG Test Loss:2.12733351607996e-05 \n",
            "Fold 1\n",
            "Epoch:1/30 AVG Training Loss:1.4132856846762476e-05 AVG Test Loss:1.3261598375872083e-09 \n",
            "Epoch:2/30 AVG Training Loss:1.3940837174939043e-05 AVG Test Loss:1.148597836142973e-09 \n",
            "Epoch:3/30 AVG Training Loss:1.4031893624164102e-05 AVG Test Loss:1.229597035541355e-09 \n",
            "Epoch:4/30 AVG Training Loss:1.3951956228200274e-05 AVG Test Loss:1.1968771343588305e-09 \n",
            "Epoch:5/30 AVG Training Loss:1.392963669056195e-05 AVG Test Loss:1.904098202184222e-09 \n",
            "Epoch:6/30 AVG Training Loss:1.3926955476946134e-05 AVG Test Loss:1.0657871337481478e-09 \n",
            "Epoch:7/30 AVG Training Loss:1.39051889999661e-05 AVG Test Loss:1.492369478512626e-09 \n",
            "Epoch:8/30 AVG Training Loss:1.388898740332343e-05 AVG Test Loss:9.507738825679213e-10 \n",
            "Epoch:9/30 AVG Training Loss:1.3911211829252252e-05 AVG Test Loss:8.831224068263345e-10 \n",
            "Epoch:10/30 AVG Training Loss:1.3908855530096858e-05 AVG Test Loss:9.606418831155878e-10 \n",
            "Epoch:11/30 AVG Training Loss:1.387286703130798e-05 AVG Test Loss:8.592451551161324e-10 \n",
            "Epoch:12/30 AVG Training Loss:1.3878665994459176e-05 AVG Test Loss:7.561768956828919e-10 \n",
            "Epoch:13/30 AVG Training Loss:1.3885980713804088e-05 AVG Test Loss:8.634592708235907e-10 \n",
            "Epoch:14/30 AVG Training Loss:1.3863844390963894e-05 AVG Test Loss:8.909702145806529e-10 \n",
            "Epoch:15/30 AVG Training Loss:1.3868237813052322e-05 AVG Test Loss:9.775709668204176e-10 \n",
            "Epoch:16/30 AVG Training Loss:1.386919551856673e-05 AVG Test Loss:7.087802677088276e-10 \n",
            "Epoch:17/30 AVG Training Loss:1.3863314716166599e-05 AVG Test Loss:7.871078945882656e-10 \n",
            "Epoch:18/30 AVG Training Loss:1.3858375058260118e-05 AVG Test Loss:6.631310340431461e-10 \n",
            "Epoch:19/30 AVG Training Loss:1.3859525459467808e-05 AVG Test Loss:8.049998695069421e-10 \n",
            "Epoch:20/30 AVG Training Loss:1.3863300039645345e-05 AVG Test Loss:7.19462050575863e-10 \n",
            "Epoch:21/30 AVG Training Loss:1.3857131040415663e-05 AVG Test Loss:2.0837504067964928e-09 \n",
            "Epoch:22/30 AVG Training Loss:1.3855460443969758e-05 AVG Test Loss:6.376188989970224e-10 \n",
            "Epoch:23/30 AVG Training Loss:1.3856120640670985e-05 AVG Test Loss:7.850367661473291e-10 \n",
            "Epoch:24/30 AVG Training Loss:1.3856076037399041e-05 AVG Test Loss:8.603675334530614e-10 \n",
            "Epoch:25/30 AVG Training Loss:1.3854647539950981e-05 AVG Test Loss:5.979683221387042e-10 \n",
            "Epoch:26/30 AVG Training Loss:1.3854519662554777e-05 AVG Test Loss:5.786264463767425e-10 \n",
            "Epoch:27/30 AVG Training Loss:1.3854932086696149e-05 AVG Test Loss:6.018082247104318e-10 \n",
            "Epoch:28/30 AVG Training Loss:1.3855021409576579e-05 AVG Test Loss:1.9949949977229557e-09 \n",
            "Epoch:29/30 AVG Training Loss:1.385420768315332e-05 AVG Test Loss:6.981172588959779e-10 \n",
            "Epoch:30/30 AVG Training Loss:1.3854688252645373e-05 AVG Test Loss:6.95859210504831e-10 \n",
            "Fold 2\n",
            "Epoch:1/30 AVG Training Loss:1.270011367641568e-05 AVG Test Loss:1.038410011507944e-05 \n",
            "Epoch:2/30 AVG Training Loss:1.2700064620586614e-05 AVG Test Loss:1.0384101056959297e-05 \n",
            "Epoch:3/30 AVG Training Loss:1.2699930707902748e-05 AVG Test Loss:1.0384089632202174e-05 \n",
            "Epoch:4/30 AVG Training Loss:1.2699931351597412e-05 AVG Test Loss:1.0384070572533803e-05 \n",
            "Epoch:5/30 AVG Training Loss:1.2699778306731262e-05 AVG Test Loss:1.0384072799544541e-05 \n",
            "Epoch:6/30 AVG Training Loss:1.2699845241121865e-05 AVG Test Loss:1.038406399946509e-05 \n",
            "Epoch:7/30 AVG Training Loss:1.2699588299535988e-05 AVG Test Loss:1.0384065898804682e-05 \n",
            "Epoch:8/30 AVG Training Loss:1.2699601533354758e-05 AVG Test Loss:1.0384054593973784e-05 \n",
            "Epoch:9/30 AVG Training Loss:1.2699588998030697e-05 AVG Test Loss:1.0384072425155589e-05 \n",
            "Epoch:10/30 AVG Training Loss:1.2699398959290764e-05 AVG Test Loss:1.0384045930671636e-05 \n",
            "Epoch:11/30 AVG Training Loss:1.2699504713850564e-05 AVG Test Loss:1.0384038640539708e-05 \n",
            "Epoch:12/30 AVG Training Loss:1.2699345574917325e-05 AVG Test Loss:1.038404249237185e-05 \n",
            "Epoch:13/30 AVG Training Loss:1.2699316054107265e-05 AVG Test Loss:1.0384036632403675e-05 \n",
            "Epoch:14/30 AVG Training Loss:1.2699338368151411e-05 AVG Test Loss:1.0384034559270436e-05 \n",
            "Epoch:15/30 AVG Training Loss:1.2699265962557623e-05 AVG Test Loss:1.038404134227639e-05 \n",
            "Epoch:16/30 AVG Training Loss:1.2699284141923305e-05 AVG Test Loss:1.0384026737280983e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.2699384327008759e-05 AVG Test Loss:1.0384013402647992e-05 \n",
            "Epoch:18/30 AVG Training Loss:1.2699260691825462e-05 AVG Test Loss:1.0384008329873164e-05 \n",
            "Epoch:19/30 AVG Training Loss:1.2699191766719932e-05 AVG Test Loss:1.0384012872344172e-05 \n",
            "Epoch:20/30 AVG Training Loss:1.2699251362404335e-05 AVG Test Loss:1.0384004223267468e-05 \n",
            "Epoch:21/30 AVG Training Loss:1.2699208454330308e-05 AVG Test Loss:1.038400794058005e-05 \n",
            "Epoch:22/30 AVG Training Loss:1.269920326789169e-05 AVG Test Loss:1.0384001203720379e-05 \n",
            "Epoch:23/30 AVG Training Loss:1.2699173542887151e-05 AVG Test Loss:1.038399944371638e-05 \n",
            "Epoch:24/30 AVG Training Loss:1.2699174900566332e-05 AVG Test Loss:1.0383990865515528e-05 \n",
            "Epoch:25/30 AVG Training Loss:1.2699155366181002e-05 AVG Test Loss:1.0383987320347185e-05 \n",
            "Epoch:26/30 AVG Training Loss:1.2699144795663972e-05 AVG Test Loss:1.038398615956401e-05 \n",
            "Epoch:27/30 AVG Training Loss:1.2699134687027717e-05 AVG Test Loss:1.0383976287203699e-05 \n",
            "Epoch:28/30 AVG Training Loss:1.2699146424441784e-05 AVG Test Loss:1.0383975192661095e-05 \n",
            "Epoch:29/30 AVG Training Loss:1.2699126584692804e-05 AVG Test Loss:1.038398595159114e-05 \n",
            "Epoch:30/30 AVG Training Loss:1.2699136476524018e-05 AVG Test Loss:1.0383969748679076e-05 \n",
            "Fold 3\n",
            "Epoch:1/30 AVG Training Loss:1.3853562963401884e-05 AVG Test Loss:1.9895351284477005e-10 \n",
            "Epoch:2/30 AVG Training Loss:1.3853543620128258e-05 AVG Test Loss:1.757697110741671e-10 \n",
            "Epoch:3/30 AVG Training Loss:1.3853548840495257e-05 AVG Test Loss:1.747662223609809e-10 \n",
            "Epoch:4/30 AVG Training Loss:1.3853540609216233e-05 AVG Test Loss:1.7214261643920868e-10 \n",
            "Epoch:5/30 AVG Training Loss:1.3853541777814783e-05 AVG Test Loss:1.7054847244718076e-10 \n",
            "Epoch:6/30 AVG Training Loss:1.385353576414623e-05 AVG Test Loss:1.8227616710776468e-10 \n",
            "Epoch:7/30 AVG Training Loss:1.3853530203759335e-05 AVG Test Loss:1.772982047690964e-10 \n",
            "Epoch:8/30 AVG Training Loss:1.3853531752104788e-05 AVG Test Loss:1.7880891523106114e-10 \n",
            "Epoch:9/30 AVG Training Loss:1.3853525000402141e-05 AVG Test Loss:1.689998523462351e-10 \n",
            "Epoch:10/30 AVG Training Loss:1.3853517979273464e-05 AVG Test Loss:1.7603554076653892e-10 \n",
            "Epoch:11/30 AVG Training Loss:1.3853516207179879e-05 AVG Test Loss:1.625459237020231e-10 \n",
            "Epoch:12/30 AVG Training Loss:1.3853512097709125e-05 AVG Test Loss:1.8360264970615847e-10 \n",
            "Epoch:13/30 AVG Training Loss:1.3853509084090824e-05 AVG Test Loss:1.6644640697075211e-10 \n",
            "Epoch:14/30 AVG Training Loss:1.3853506177151017e-05 AVG Test Loss:1.6140655525294813e-10 \n",
            "Epoch:15/30 AVG Training Loss:1.3853501351043828e-05 AVG Test Loss:1.5239546161894373e-10 \n",
            "Epoch:16/30 AVG Training Loss:1.3853501997700503e-05 AVG Test Loss:1.5918597137935566e-10 \n",
            "Epoch:17/30 AVG Training Loss:1.3853498460417332e-05 AVG Test Loss:1.7656093582314846e-10 \n",
            "Epoch:18/30 AVG Training Loss:1.3853495371824728e-05 AVG Test Loss:1.5882483998443916e-10 \n",
            "Epoch:19/30 AVG Training Loss:1.385349393548767e-05 AVG Test Loss:1.586406525927537e-10 \n",
            "Epoch:20/30 AVG Training Loss:1.3853490586581026e-05 AVG Test Loss:1.5334254579456186e-10 \n",
            "Epoch:21/30 AVG Training Loss:1.3853488507706223e-05 AVG Test Loss:1.498518329574371e-10 \n",
            "Epoch:22/30 AVG Training Loss:1.3853485409941339e-05 AVG Test Loss:1.6393005782690816e-10 \n",
            "Epoch:23/30 AVG Training Loss:1.3853482077179776e-05 AVG Test Loss:1.4320736599398638e-10 \n",
            "Epoch:24/30 AVG Training Loss:1.3853481457187323e-05 AVG Test Loss:1.453053553915364e-10 \n",
            "Epoch:25/30 AVG Training Loss:1.3853481545060038e-05 AVG Test Loss:1.5946322588185948e-10 \n",
            "Epoch:26/30 AVG Training Loss:1.3853478063383818e-05 AVG Test Loss:1.5957453872989737e-10 \n",
            "Epoch:27/30 AVG Training Loss:1.3853475707311519e-05 AVG Test Loss:1.4288097749659867e-10 \n",
            "Epoch:28/30 AVG Training Loss:1.3853474822711093e-05 AVG Test Loss:1.432817425402749e-10 \n",
            "Epoch:29/30 AVG Training Loss:1.3853473178603172e-05 AVG Test Loss:1.4103973110003795e-10 \n",
            "Epoch:30/30 AVG Training Loss:1.3853471245813255e-05 AVG Test Loss:1.5051539988352596e-10 \n",
            "Fold 4\n",
            "Epoch:1/30 AVG Training Loss:1.2699029550592179e-05 AVG Test Loss:1.03838892948734e-05 \n",
            "Epoch:2/30 AVG Training Loss:1.2699027063861299e-05 AVG Test Loss:1.0383887999224183e-05 \n",
            "Epoch:3/30 AVG Training Loss:1.2699024753151182e-05 AVG Test Loss:1.0383886466217723e-05 \n",
            "Epoch:4/30 AVG Training Loss:1.2699022927640375e-05 AVG Test Loss:1.0383885633452849e-05 \n",
            "Epoch:5/30 AVG Training Loss:1.2699020709553977e-05 AVG Test Loss:1.038388614699506e-05 \n",
            "Epoch:6/30 AVG Training Loss:1.2699017862488381e-05 AVG Test Loss:1.0383884173972968e-05 \n",
            "Epoch:7/30 AVG Training Loss:1.2699018569212074e-05 AVG Test Loss:1.0383883188537143e-05 \n",
            "Epoch:8/30 AVG Training Loss:1.2699017634531232e-05 AVG Test Loss:1.0383882567340837e-05 \n",
            "Epoch:9/30 AVG Training Loss:1.2699014876177702e-05 AVG Test Loss:1.0383881375267865e-05 \n",
            "Epoch:10/30 AVG Training Loss:1.2699013027565991e-05 AVG Test Loss:1.0383880317828742e-05 \n",
            "Epoch:11/30 AVG Training Loss:1.2699013434649728e-05 AVG Test Loss:1.03838792868288e-05 \n",
            "Epoch:12/30 AVG Training Loss:1.2699011644071536e-05 AVG Test Loss:1.0383878325947638e-05 \n",
            "Epoch:13/30 AVG Training Loss:1.269900966556086e-05 AVG Test Loss:1.0383877484146612e-05 \n",
            "Epoch:14/30 AVG Training Loss:1.2699009463506764e-05 AVG Test Loss:1.0383876986447916e-05 \n",
            "Epoch:15/30 AVG Training Loss:1.2699008242199568e-05 AVG Test Loss:1.0383876325042427e-05 \n",
            "Epoch:16/30 AVG Training Loss:1.2699007090130908e-05 AVG Test Loss:1.0383875667448939e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.2699006047868998e-05 AVG Test Loss:1.0383875336807704e-05 \n",
            "Epoch:18/30 AVG Training Loss:1.2699004914562037e-05 AVG Test Loss:1.0383874513973058e-05 \n",
            "Epoch:19/30 AVG Training Loss:1.2699003344769875e-05 AVG Test Loss:1.0383873403632172e-05 \n",
            "Epoch:20/30 AVG Training Loss:1.2699002632648068e-05 AVG Test Loss:1.0383872967623858e-05 \n",
            "Epoch:21/30 AVG Training Loss:1.2699001661560261e-05 AVG Test Loss:1.0383871820543221e-05 \n",
            "Epoch:22/30 AVG Training Loss:1.2699000805505458e-05 AVG Test Loss:1.0383870389096384e-05 \n",
            "Epoch:23/30 AVG Training Loss:1.269899978923947e-05 AVG Test Loss:1.038387017890224e-05 \n",
            "Epoch:24/30 AVG Training Loss:1.2698998663768783e-05 AVG Test Loss:1.038386929346658e-05 \n",
            "Epoch:25/30 AVG Training Loss:1.269899801482873e-05 AVG Test Loss:1.0383869231135395e-05 \n",
            "Epoch:26/30 AVG Training Loss:1.2698996664604814e-05 AVG Test Loss:1.0383867759690632e-05 \n",
            "Epoch:27/30 AVG Training Loss:1.2698995696201292e-05 AVG Test Loss:1.0383867818458879e-05 \n",
            "Epoch:28/30 AVG Training Loss:1.2698995260791808e-05 AVG Test Loss:1.038386672726992e-05 \n",
            "Epoch:29/30 AVG Training Loss:1.2698994520292865e-05 AVG Test Loss:1.0383866647669112e-05 \n",
            "Epoch:30/30 AVG Training Loss:1.2698993364146583e-05 AVG Test Loss:1.0383866028384936e-05 \n",
            "Fold 5\n",
            "Epoch:1/30 AVG Training Loss:1.1543158326978169e-05 AVG Test Loss:2.0790123767658393e-05 \n",
            "Epoch:2/30 AVG Training Loss:1.1543157242565142e-05 AVG Test Loss:2.079012505562608e-05 \n",
            "Epoch:3/30 AVG Training Loss:1.1543156339564014e-05 AVG Test Loss:2.0790128271201728e-05 \n",
            "Epoch:4/30 AVG Training Loss:1.1543155544386588e-05 AVG Test Loss:2.0790129809011755e-05 \n",
            "Epoch:5/30 AVG Training Loss:1.154315474924439e-05 AVG Test Loss:2.0790128768899903e-05 \n",
            "Epoch:6/30 AVG Training Loss:1.1543154042439734e-05 AVG Test Loss:2.079013667767201e-05 \n",
            "Epoch:7/30 AVG Training Loss:1.1543153322341718e-05 AVG Test Loss:2.079013628899857e-05 \n",
            "Epoch:8/30 AVG Training Loss:1.1543152533489994e-05 AVG Test Loss:2.079013536757004e-05 \n",
            "Epoch:9/30 AVG Training Loss:1.1543151994938448e-05 AVG Test Loss:2.0790142195452423e-05 \n",
            "Epoch:10/30 AVG Training Loss:1.154315127103468e-05 AVG Test Loss:2.0790144425791357e-05 \n",
            "Epoch:11/30 AVG Training Loss:1.1543150775300974e-05 AVG Test Loss:2.0790152890601495e-05 \n",
            "Epoch:12/30 AVG Training Loss:1.1543149976005305e-05 AVG Test Loss:2.0790155309976792e-05 \n",
            "Epoch:13/30 AVG Training Loss:1.1543149368626172e-05 AVG Test Loss:2.0790160345984404e-05 \n",
            "Epoch:14/30 AVG Training Loss:1.154314879360194e-05 AVG Test Loss:2.0790159349354024e-05 \n",
            "Epoch:15/30 AVG Training Loss:1.1543148209341465e-05 AVG Test Loss:2.0790165712035727e-05 \n",
            "Epoch:16/30 AVG Training Loss:1.1543147663633238e-05 AVG Test Loss:2.079016949317523e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.1543147252819626e-05 AVG Test Loss:2.0790170138665468e-05 \n",
            "Epoch:18/30 AVG Training Loss:1.1543146646309021e-05 AVG Test Loss:2.079017328113785e-05 \n",
            "Epoch:19/30 AVG Training Loss:1.1543145795735628e-05 AVG Test Loss:2.0790180329284832e-05 \n",
            "Epoch:20/30 AVG Training Loss:1.1543145314814773e-05 AVG Test Loss:2.0790181314119398e-05 \n",
            "Epoch:21/30 AVG Training Loss:1.1543144921217538e-05 AVG Test Loss:2.079019174446739e-05 \n",
            "Epoch:22/30 AVG Training Loss:1.1543144340866189e-05 AVG Test Loss:2.0790196164893102e-05 \n",
            "Epoch:23/30 AVG Training Loss:1.1543144039101897e-05 AVG Test Loss:2.0790199587136365e-05 \n",
            "Epoch:24/30 AVG Training Loss:1.1543143439124503e-05 AVG Test Loss:2.0790206400259808e-05 \n",
            "Epoch:25/30 AVG Training Loss:1.1543143031143535e-05 AVG Test Loss:2.0790207397951066e-05 \n",
            "Epoch:26/30 AVG Training Loss:1.1543142536926274e-05 AVG Test Loss:2.079021074978562e-05 \n",
            "Epoch:27/30 AVG Training Loss:1.1543142152877278e-05 AVG Test Loss:2.0790221690061053e-05 \n",
            "Epoch:28/30 AVG Training Loss:1.1543141492813322e-05 AVG Test Loss:2.0790226729950884e-05 \n",
            "Epoch:29/30 AVG Training Loss:1.1543141163420874e-05 AVG Test Loss:2.0790224449753694e-05 \n",
            "Epoch:30/30 AVG Training Loss:1.154314066532677e-05 AVG Test Loss:2.079022540595966e-05 \n",
            "Fold 6\n",
            "Epoch:1/30 AVG Training Loss:1.2697465183602551e-05 AVG Test Loss:1.0395065349373126e-05 \n",
            "Epoch:2/30 AVG Training Loss:1.2697460425281457e-05 AVG Test Loss:1.0395066001114023e-05 \n",
            "Epoch:3/30 AVG Training Loss:1.269745738339241e-05 AVG Test Loss:1.0395065496539073e-05 \n",
            "Epoch:4/30 AVG Training Loss:1.2697453713057978e-05 AVG Test Loss:1.0395064593296789e-05 \n",
            "Epoch:5/30 AVG Training Loss:1.2697455818480905e-05 AVG Test Loss:1.0395064549946361e-05 \n",
            "Epoch:6/30 AVG Training Loss:1.269745432229598e-05 AVG Test Loss:1.0395064437165537e-05 \n",
            "Epoch:7/30 AVG Training Loss:1.2697451796144965e-05 AVG Test Loss:1.0395063749548942e-05 \n",
            "Epoch:8/30 AVG Training Loss:1.2697453112840311e-05 AVG Test Loss:1.0395063940287784e-05 \n",
            "Epoch:9/30 AVG Training Loss:1.2697450426016718e-05 AVG Test Loss:1.0395063209117353e-05 \n",
            "Epoch:10/30 AVG Training Loss:1.2697451279186717e-05 AVG Test Loss:1.0395063012570569e-05 \n",
            "Epoch:11/30 AVG Training Loss:1.2697450478683645e-05 AVG Test Loss:1.039506276636661e-05 \n",
            "Epoch:12/30 AVG Training Loss:1.2697450250006712e-05 AVG Test Loss:1.039506262533221e-05 \n",
            "Epoch:13/30 AVG Training Loss:1.269744950242021e-05 AVG Test Loss:1.0395062341728054e-05 \n",
            "Epoch:14/30 AVG Training Loss:1.2697448171018252e-05 AVG Test Loss:1.0395061878727355e-05 \n",
            "Epoch:15/30 AVG Training Loss:1.2697448522031446e-05 AVG Test Loss:1.0395061885938703e-05 \n",
            "Epoch:16/30 AVG Training Loss:1.2697447432216939e-05 AVG Test Loss:1.0395061481912422e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.2697447419131172e-05 AVG Test Loss:1.0395061189229425e-05 \n",
            "Epoch:18/30 AVG Training Loss:1.2697446753050192e-05 AVG Test Loss:1.0395061095270066e-05 \n",
            "Epoch:19/30 AVG Training Loss:1.2697446228374801e-05 AVG Test Loss:1.0395060672960438e-05 \n",
            "Epoch:20/30 AVG Training Loss:1.2697445952385898e-05 AVG Test Loss:1.0395060554065825e-05 \n",
            "Epoch:21/30 AVG Training Loss:1.2697445491241452e-05 AVG Test Loss:1.0395060147937547e-05 \n",
            "Epoch:22/30 AVG Training Loss:1.2697445060609957e-05 AVG Test Loss:1.0395059860976542e-05 \n",
            "Epoch:23/30 AVG Training Loss:1.2697444669865867e-05 AVG Test Loss:1.039505964932352e-05 \n",
            "Epoch:24/30 AVG Training Loss:1.2697444229564638e-05 AVG Test Loss:1.03950593319414e-05 \n",
            "Epoch:25/30 AVG Training Loss:1.2697444068507252e-05 AVG Test Loss:1.0395059131202149e-05 \n",
            "Epoch:26/30 AVG Training Loss:1.269744361779267e-05 AVG Test Loss:1.0395059059237743e-05 \n",
            "Epoch:27/30 AVG Training Loss:1.2697443307533862e-05 AVG Test Loss:1.0395058781126011e-05 \n",
            "Epoch:28/30 AVG Training Loss:1.2697442755850423e-05 AVG Test Loss:1.0395058478380309e-05 \n",
            "Epoch:29/30 AVG Training Loss:1.2697442503746573e-05 AVG Test Loss:1.0395058221862406e-05 \n",
            "Epoch:30/30 AVG Training Loss:1.2697442278304313e-05 AVG Test Loss:1.0395058076090408e-05 \n",
            "Fold 7\n",
            "Epoch:1/30 AVG Training Loss:1.2697441563988923e-05 AVG Test Loss:1.0395060661086475e-05 \n",
            "Epoch:2/30 AVG Training Loss:1.2697441338558795e-05 AVG Test Loss:1.0395060350428996e-05 \n",
            "Epoch:3/30 AVG Training Loss:1.2697440788297305e-05 AVG Test Loss:1.0395060084791293e-05 \n",
            "Epoch:4/30 AVG Training Loss:1.2697440594958928e-05 AVG Test Loss:1.039505996216007e-05 \n",
            "Epoch:5/30 AVG Training Loss:1.269744030744196e-05 AVG Test Loss:1.0395059718316681e-05 \n",
            "Epoch:6/30 AVG Training Loss:1.2697439881114361e-05 AVG Test Loss:1.0395059677636503e-05 \n",
            "Epoch:7/30 AVG Training Loss:1.269743963070894e-05 AVG Test Loss:1.0395059468256253e-05 \n",
            "Epoch:8/30 AVG Training Loss:1.2697439369946417e-05 AVG Test Loss:1.0395059241547343e-05 \n",
            "Epoch:9/30 AVG Training Loss:1.2697439029659838e-05 AVG Test Loss:1.0395059032436438e-05 \n",
            "Epoch:10/30 AVG Training Loss:1.2697438732534593e-05 AVG Test Loss:1.0395058927301367e-05 \n",
            "Epoch:11/30 AVG Training Loss:1.2697438466617051e-05 AVG Test Loss:1.0395058756683675e-05 \n",
            "Epoch:12/30 AVG Training Loss:1.2697438273147245e-05 AVG Test Loss:1.0395058427569115e-05 \n",
            "Epoch:13/30 AVG Training Loss:1.2697437990731944e-05 AVG Test Loss:1.0395058095318732e-05 \n",
            "Epoch:14/30 AVG Training Loss:1.2697437655428514e-05 AVG Test Loss:1.0395058055673612e-05 \n",
            "Epoch:15/30 AVG Training Loss:1.2697437355684358e-05 AVG Test Loss:1.0395057728308687e-05 \n",
            "Epoch:16/30 AVG Training Loss:1.2697437066791703e-05 AVG Test Loss:1.0395057661966493e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.2697436922091084e-05 AVG Test Loss:1.0395057330434951e-05 \n",
            "Epoch:18/30 AVG Training Loss:1.2697436425407827e-05 AVG Test Loss:1.039505728251597e-05 \n",
            "Epoch:19/30 AVG Training Loss:1.2697436255838495e-05 AVG Test Loss:1.0395057191853232e-05 \n",
            "Epoch:20/30 AVG Training Loss:1.2697436179415156e-05 AVG Test Loss:1.0395056865170182e-05 \n",
            "Epoch:21/30 AVG Training Loss:1.269743587956552e-05 AVG Test Loss:1.0395056627836492e-05 \n",
            "Epoch:22/30 AVG Training Loss:1.269743548019558e-05 AVG Test Loss:1.0395056548048816e-05 \n",
            "Epoch:23/30 AVG Training Loss:1.2697435264704995e-05 AVG Test Loss:1.0395056320741339e-05 \n",
            "Epoch:24/30 AVG Training Loss:1.2697435145320503e-05 AVG Test Loss:1.0395056112219549e-05 \n",
            "Epoch:25/30 AVG Training Loss:1.2697434913202527e-05 AVG Test Loss:1.039505594930901e-05 \n",
            "Epoch:26/30 AVG Training Loss:1.269743459630121e-05 AVG Test Loss:1.0395055728519462e-05 \n",
            "Epoch:27/30 AVG Training Loss:1.269743431566381e-05 AVG Test Loss:1.0395055626039976e-05 \n",
            "Epoch:28/30 AVG Training Loss:1.2697434090078182e-05 AVG Test Loss:1.03950555027586e-05 \n",
            "Epoch:29/30 AVG Training Loss:1.2697433955608402e-05 AVG Test Loss:1.0395055163893406e-05 \n",
            "Epoch:30/30 AVG Training Loss:1.2697433710314655e-05 AVG Test Loss:1.0395055024354986e-05 \n",
            "Fold 8\n",
            "Epoch:1/30 AVG Training Loss:1.1543125224691374e-05 AVG Test Loss:2.0790068094858307e-05 \n",
            "Epoch:2/30 AVG Training Loss:1.1543125049556914e-05 AVG Test Loss:2.079006788265783e-05 \n",
            "Epoch:3/30 AVG Training Loss:1.1543124842777629e-05 AVG Test Loss:2.0790068761702162e-05 \n",
            "Epoch:4/30 AVG Training Loss:1.1543124619742646e-05 AVG Test Loss:2.079006855056148e-05 \n",
            "Epoch:5/30 AVG Training Loss:1.1543124393232959e-05 AVG Test Loss:2.079006841306545e-05 \n",
            "Epoch:6/30 AVG Training Loss:1.1543124198757708e-05 AVG Test Loss:2.0790068252473405e-05 \n",
            "Epoch:7/30 AVG Training Loss:1.1543123988674263e-05 AVG Test Loss:2.079006808449889e-05 \n",
            "Epoch:8/30 AVG Training Loss:1.1543123771269593e-05 AVG Test Loss:2.0790067925362765e-05 \n",
            "Epoch:9/30 AVG Training Loss:1.1543123548903212e-05 AVG Test Loss:2.0790067819594015e-05 \n",
            "Epoch:10/30 AVG Training Loss:1.154312340967564e-05 AVG Test Loss:2.0790066549723424e-05 \n",
            "Epoch:11/30 AVG Training Loss:1.154312321776147e-05 AVG Test Loss:2.0790066430103164e-05 \n",
            "Epoch:12/30 AVG Training Loss:1.1543123006834425e-05 AVG Test Loss:2.079006735213367e-05 \n",
            "Epoch:13/30 AVG Training Loss:1.1543122827550205e-05 AVG Test Loss:2.0790067172872773e-05 \n",
            "Epoch:14/30 AVG Training Loss:1.1543122649952004e-05 AVG Test Loss:2.0790066000348628e-05 \n",
            "Epoch:15/30 AVG Training Loss:1.1543122442635842e-05 AVG Test Loss:2.079006686974244e-05 \n",
            "Epoch:16/30 AVG Training Loss:1.1543122322165968e-05 AVG Test Loss:2.0790066675072848e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.154312209479802e-05 AVG Test Loss:2.0790065534314113e-05 \n",
            "Epoch:18/30 AVG Training Loss:1.1543121917660047e-05 AVG Test Loss:2.0790066385371232e-05 \n",
            "Epoch:19/30 AVG Training Loss:1.154312172223208e-05 AVG Test Loss:2.0790065262569596e-05 \n",
            "Epoch:20/30 AVG Training Loss:1.1543121574652105e-05 AVG Test Loss:2.0790065042470686e-05 \n",
            "Epoch:21/30 AVG Training Loss:1.1543121381614366e-05 AVG Test Loss:2.0790064939740403e-05 \n",
            "Epoch:22/30 AVG Training Loss:1.1543121244054182e-05 AVG Test Loss:2.079006571288665e-05 \n",
            "Epoch:23/30 AVG Training Loss:1.1543121042415373e-05 AVG Test Loss:2.0790065619203443e-05 \n",
            "Epoch:24/30 AVG Training Loss:1.1543120884939147e-05 AVG Test Loss:2.0790065520077955e-05 \n",
            "Epoch:25/30 AVG Training Loss:1.1543120766433022e-05 AVG Test Loss:2.079006535710172e-05 \n",
            "Epoch:26/30 AVG Training Loss:1.1543120589022655e-05 AVG Test Loss:2.079006517337325e-05 \n",
            "Epoch:27/30 AVG Training Loss:1.1543120421221376e-05 AVG Test Loss:2.0790065019955348e-05 \n",
            "Epoch:28/30 AVG Training Loss:1.1543120264784964e-05 AVG Test Loss:2.0790064873571497e-05 \n",
            "Epoch:29/30 AVG Training Loss:1.154312005525174e-05 AVG Test Loss:2.079006474589776e-05 \n",
            "Epoch:30/30 AVG Training Loss:1.15431199337251e-05 AVG Test Loss:2.079006463650316e-05 \n",
            "Fold 9\n",
            "Epoch:1/30 AVG Training Loss:1.1543119946963011e-05 AVG Test Loss:2.0790062848651768e-05 \n",
            "Epoch:2/30 AVG Training Loss:1.1543119790835745e-05 AVG Test Loss:2.079006273982421e-05 \n",
            "Epoch:3/30 AVG Training Loss:1.1543119560562642e-05 AVG Test Loss:2.0790062638908037e-05 \n",
            "Epoch:4/30 AVG Training Loss:1.1543119424069274e-05 AVG Test Loss:2.0790062531912705e-05 \n",
            "Epoch:5/30 AVG Training Loss:1.1543119264438335e-05 AVG Test Loss:2.0790062414038238e-05 \n",
            "Epoch:6/30 AVG Training Loss:1.1543119207676734e-05 AVG Test Loss:2.0790062250059642e-05 \n",
            "Epoch:7/30 AVG Training Loss:1.1543119015570886e-05 AVG Test Loss:2.0790062192846158e-05 \n",
            "Epoch:8/30 AVG Training Loss:1.154311877170425e-05 AVG Test Loss:2.0790062100701825e-05 \n",
            "Epoch:9/30 AVG Training Loss:1.1543118627524753e-05 AVG Test Loss:2.07900620188171e-05 \n",
            "Epoch:10/30 AVG Training Loss:1.1543118426336267e-05 AVG Test Loss:2.079006196833692e-05 \n",
            "Epoch:11/30 AVG Training Loss:1.1543118303418868e-05 AVG Test Loss:2.0790061826508e-05 \n",
            "Epoch:12/30 AVG Training Loss:1.1543118188522521e-05 AVG Test Loss:2.07900616381688e-05 \n",
            "Epoch:13/30 AVG Training Loss:1.1543118132684188e-05 AVG Test Loss:2.0790061502677336e-05 \n",
            "Epoch:14/30 AVG Training Loss:1.1543117873784768e-05 AVG Test Loss:2.0790061399163683e-05 \n",
            "Epoch:15/30 AVG Training Loss:1.15431177832157e-05 AVG Test Loss:2.07900612519158e-05 \n",
            "Epoch:16/30 AVG Training Loss:1.1543117601707623e-05 AVG Test Loss:2.079006115575549e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.154311748479939e-05 AVG Test Loss:2.0790061057544626e-05 \n",
            "Epoch:18/30 AVG Training Loss:1.1543117341531104e-05 AVG Test Loss:2.0790060977688887e-05 \n",
            "Epoch:19/30 AVG Training Loss:1.1543117193999005e-05 AVG Test Loss:2.079006085729463e-05 \n",
            "Epoch:20/30 AVG Training Loss:1.15431170745524e-05 AVG Test Loss:2.079006082340616e-05 \n",
            "Epoch:21/30 AVG Training Loss:1.1543116959723754e-05 AVG Test Loss:2.0790060661466382e-05 \n",
            "Epoch:22/30 AVG Training Loss:1.1543116822978465e-05 AVG Test Loss:2.0790060602771397e-05 \n",
            "Epoch:23/30 AVG Training Loss:1.1543116654809223e-05 AVG Test Loss:2.0790060557264785e-05 \n",
            "Epoch:24/30 AVG Training Loss:1.1543116591647687e-05 AVG Test Loss:2.0790060381307355e-05 \n",
            "Epoch:25/30 AVG Training Loss:1.1543116414733845e-05 AVG Test Loss:2.0790060287500553e-05 \n",
            "Epoch:26/30 AVG Training Loss:1.1543116315583578e-05 AVG Test Loss:2.0790060129075085e-05 \n",
            "Epoch:27/30 AVG Training Loss:1.1543116166692757e-05 AVG Test Loss:2.0790060036311482e-05 \n",
            "Epoch:28/30 AVG Training Loss:1.1543116066577024e-05 AVG Test Loss:2.0790059993575702e-05 \n",
            "Epoch:29/30 AVG Training Loss:1.1543115919130256e-05 AVG Test Loss:2.0790059860913873e-05 \n",
            "Epoch:30/30 AVG Training Loss:1.154311580255781e-05 AVG Test Loss:2.0790059783703825e-05 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainClassifier(\"Victim\", victim, victim_model, victim_optimizer, victim_metrics, victim_foldperf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QARDAYvlqSb",
        "outputId": "ab185cc8-7312-4002-c8b3-47d5c9276038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0\n",
            "Epoch:1/30 AVG Training Loss:0.060170489276044396 AVG Test Loss:0.03663204667393225 \n",
            "Epoch:2/30 AVG Training Loss:0.025880786302429154 AVG Test Loss:0.01674265445993233 \n",
            "Epoch:3/30 AVG Training Loss:0.01083417883767057 AVG Test Loss:0.006708156280834134 \n",
            "Epoch:4/30 AVG Training Loss:0.004373089040651179 AVG Test Loss:0.0028291578013008674 \n",
            "Epoch:5/30 AVG Training Loss:0.0019025800053006118 AVG Test Loss:0.0012540731837060192 \n",
            "Epoch:6/30 AVG Training Loss:0.0008968813973951067 AVG Test Loss:0.0005747772811077001 \n",
            "Epoch:7/30 AVG Training Loss:0.0004640780551565798 AVG Test Loss:0.0002604128544351381 \n",
            "Epoch:8/30 AVG Training Loss:0.0002726447299827811 AVG Test Loss:0.0001381766827610124 \n",
            "Epoch:9/30 AVG Training Loss:0.0001750795219033089 AVG Test Loss:9.04699477529107e-05 \n",
            "Epoch:10/30 AVG Training Loss:0.00011290374947047033 AVG Test Loss:5.0310474798007e-05 \n",
            "Epoch:11/30 AVG Training Loss:8.005392332696273e-05 AVG Test Loss:3.220296574127918e-05 \n",
            "Epoch:12/30 AVG Training Loss:5.823079625110945e-05 AVG Test Loss:2.4023332038529792e-05 \n",
            "Epoch:13/30 AVG Training Loss:4.6081215665595694e-05 AVG Test Loss:2.042970449157951e-05 \n",
            "Epoch:14/30 AVG Training Loss:3.731703216917133e-05 AVG Test Loss:2.0482279781133294e-05 \n",
            "Epoch:15/30 AVG Training Loss:3.2678993962450345e-05 AVG Test Loss:1.9726828633211435e-05 \n",
            "Epoch:16/30 AVG Training Loss:3.0503687948182222e-05 AVG Test Loss:1.7167422578043264e-05 \n",
            "Epoch:17/30 AVG Training Loss:2.4189363857739885e-05 AVG Test Loss:2.068507741337791e-05 \n",
            "Epoch:18/30 AVG Training Loss:2.2508771816919314e-05 AVG Test Loss:2.040650924942161e-05 \n",
            "Epoch:19/30 AVG Training Loss:2.0742335834267658e-05 AVG Test Loss:1.693174995005249e-05 \n",
            "Epoch:20/30 AVG Training Loss:2.0062653157550478e-05 AVG Test Loss:1.70809089539084e-05 \n",
            "Epoch:21/30 AVG Training Loss:1.8931874821805707e-05 AVG Test Loss:1.9212955406638255e-05 \n",
            "Epoch:22/30 AVG Training Loss:1.8666632188758164e-05 AVG Test Loss:1.6376124620052884e-05 \n",
            "Epoch:23/30 AVG Training Loss:1.8680929269889446e-05 AVG Test Loss:1.6364313748224295e-05 \n",
            "Epoch:24/30 AVG Training Loss:1.829272390938005e-05 AVG Test Loss:1.6645880929281616e-05 \n",
            "Epoch:25/30 AVG Training Loss:1.8374753904984425e-05 AVG Test Loss:1.6494690293535723e-05 \n",
            "Epoch:26/30 AVG Training Loss:1.821298285108122e-05 AVG Test Loss:1.6535043608295374e-05 \n",
            "Epoch:27/30 AVG Training Loss:1.834089259242724e-05 AVG Test Loss:1.694796439176545e-05 \n",
            "Epoch:28/30 AVG Training Loss:1.824051284406719e-05 AVG Test Loss:1.6350600261307664e-05 \n",
            "Epoch:29/30 AVG Training Loss:1.82307961022442e-05 AVG Test Loss:1.6365915440679966e-05 \n",
            "Epoch:30/30 AVG Training Loss:1.817935662433508e-05 AVG Test Loss:1.6301808963071198e-05 \n",
            "Fold 1\n",
            "Epoch:1/30 AVG Training Loss:1.4535934350445114e-05 AVG Test Loss:4.885838045894842e-05 \n",
            "Epoch:2/30 AVG Training Loss:1.4525035818105283e-05 AVG Test Loss:4.881286006157509e-05 \n",
            "Epoch:3/30 AVG Training Loss:1.4522840972259081e-05 AVG Test Loss:4.882720348724709e-05 \n",
            "Epoch:4/30 AVG Training Loss:1.4505190950528616e-05 AVG Test Loss:4.8814637351550935e-05 \n",
            "Epoch:5/30 AVG Training Loss:1.449977458559431e-05 AVG Test Loss:4.882404618037284e-05 \n",
            "Epoch:6/30 AVG Training Loss:1.449641574526476e-05 AVG Test Loss:4.881927105614792e-05 \n",
            "Epoch:7/30 AVG Training Loss:1.449764768432749e-05 AVG Test Loss:4.8816220299788924e-05 \n",
            "Epoch:8/30 AVG Training Loss:1.4490501854580965e-05 AVG Test Loss:4.8815933603965654e-05 \n",
            "Epoch:9/30 AVG Training Loss:1.4493045021428129e-05 AVG Test Loss:4.88143527079784e-05 \n",
            "Epoch:10/30 AVG Training Loss:1.4488757439693073e-05 AVG Test Loss:4.881856564896124e-05 \n",
            "Epoch:11/30 AVG Training Loss:1.448991827059806e-05 AVG Test Loss:4.881111616247721e-05 \n",
            "Epoch:12/30 AVG Training Loss:1.4488768838098356e-05 AVG Test Loss:4.88111095602551e-05 \n",
            "Epoch:13/30 AVG Training Loss:1.4487427374503647e-05 AVG Test Loss:4.881071914213243e-05 \n",
            "Epoch:14/30 AVG Training Loss:1.4487210196677222e-05 AVG Test Loss:4.881035217994571e-05 \n",
            "Epoch:15/30 AVG Training Loss:1.4486659384247471e-05 AVG Test Loss:4.8810543816904596e-05 \n",
            "Epoch:16/30 AVG Training Loss:1.448639316300697e-05 AVG Test Loss:4.881120618259817e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.4485735421509893e-05 AVG Test Loss:4.881049178429997e-05 \n",
            "Epoch:18/30 AVG Training Loss:1.4485826020596832e-05 AVG Test Loss:4.8810043507252836e-05 \n",
            "Epoch:19/30 AVG Training Loss:1.4485281620978512e-05 AVG Test Loss:4.8810677260399904e-05 \n",
            "Epoch:20/30 AVG Training Loss:1.4485182369447735e-05 AVG Test Loss:4.8810010285443153e-05 \n",
            "Epoch:21/30 AVG Training Loss:1.4485154457386334e-05 AVG Test Loss:4.881009162278968e-05 \n",
            "Epoch:22/30 AVG Training Loss:1.4484900839692927e-05 AVG Test Loss:4.8810254819609575e-05 \n",
            "Epoch:23/30 AVG Training Loss:1.4484741639314535e-05 AVG Test Loss:4.88102657197101e-05 \n",
            "Epoch:24/30 AVG Training Loss:1.4484797532445802e-05 AVG Test Loss:4.881003803575075e-05 \n",
            "Epoch:25/30 AVG Training Loss:1.4484691743419218e-05 AVG Test Loss:4.8810187737160814e-05 \n",
            "Epoch:26/30 AVG Training Loss:1.4484810483123588e-05 AVG Test Loss:4.880991959897527e-05 \n",
            "Epoch:27/30 AVG Training Loss:1.4484625346642506e-05 AVG Test Loss:4.881017795820156e-05 \n",
            "Epoch:28/30 AVG Training Loss:1.448468701075117e-05 AVG Test Loss:4.880985051709277e-05 \n",
            "Epoch:29/30 AVG Training Loss:1.4484514807477745e-05 AVG Test Loss:4.8810036136429036e-05 \n",
            "Epoch:30/30 AVG Training Loss:1.448449715743622e-05 AVG Test Loss:4.880987235482855e-05 \n",
            "Fold 2\n",
            "Epoch:1/30 AVG Training Loss:1.9912152172176978e-05 AVG Test Loss:5.09802634064905e-10 \n",
            "Epoch:2/30 AVG Training Loss:1.9912121809463817e-05 AVG Test Loss:5.466279361946116e-10 \n",
            "Epoch:3/30 AVG Training Loss:1.991211913603799e-05 AVG Test Loss:4.952817956137537e-10 \n",
            "Epoch:4/30 AVG Training Loss:1.9912061932164223e-05 AVG Test Loss:4.778125847548022e-10 \n",
            "Epoch:5/30 AVG Training Loss:1.9912030070060887e-05 AVG Test Loss:4.6359059914819395e-10 \n",
            "Epoch:6/30 AVG Training Loss:1.9912004680276974e-05 AVG Test Loss:4.868797890044675e-10 \n",
            "Epoch:7/30 AVG Training Loss:1.9911990805309525e-05 AVG Test Loss:4.4311968477778466e-10 \n",
            "Epoch:8/30 AVG Training Loss:1.9911963212364696e-05 AVG Test Loss:4.329636481846227e-10 \n",
            "Epoch:9/30 AVG Training Loss:1.9911946021521986e-05 AVG Test Loss:4.249872099835334e-10 \n",
            "Epoch:10/30 AVG Training Loss:1.9911928775097327e-05 AVG Test Loss:4.159820582862301e-10 \n",
            "Epoch:11/30 AVG Training Loss:1.991191736557212e-05 AVG Test Loss:4.270655186598199e-10 \n",
            "Epoch:12/30 AVG Training Loss:1.9911889717104515e-05 AVG Test Loss:3.956406219001814e-10 \n",
            "Epoch:13/30 AVG Training Loss:1.9911908562624268e-05 AVG Test Loss:3.8905514439787945e-10 \n",
            "Epoch:14/30 AVG Training Loss:1.991188556988606e-05 AVG Test Loss:3.833294158319339e-10 \n",
            "Epoch:15/30 AVG Training Loss:1.9911882306316867e-05 AVG Test Loss:3.7833735545339627e-10 \n",
            "Epoch:16/30 AVG Training Loss:1.9911863622571514e-05 AVG Test Loss:3.703788992900114e-10 \n",
            "Epoch:17/30 AVG Training Loss:1.9911847460460883e-05 AVG Test Loss:3.5961246909913026e-10 \n",
            "Epoch:18/30 AVG Training Loss:1.991184072605511e-05 AVG Test Loss:3.5292175273306554e-10 \n",
            "Epoch:19/30 AVG Training Loss:1.9911840162121453e-05 AVG Test Loss:3.488458928033695e-10 \n",
            "Epoch:20/30 AVG Training Loss:1.9911820027212637e-05 AVG Test Loss:3.42086978259503e-10 \n",
            "Epoch:21/30 AVG Training Loss:1.99118231732495e-05 AVG Test Loss:3.410239671514574e-10 \n",
            "Epoch:22/30 AVG Training Loss:1.991180882840315e-05 AVG Test Loss:3.2919638981584587e-10 \n",
            "Epoch:23/30 AVG Training Loss:1.991180770320976e-05 AVG Test Loss:3.290306393398837e-10 \n",
            "Epoch:24/30 AVG Training Loss:1.9911798487177148e-05 AVG Test Loss:3.203260185351252e-10 \n",
            "Epoch:25/30 AVG Training Loss:1.991178848289743e-05 AVG Test Loss:3.11754194258378e-10 \n",
            "Epoch:26/30 AVG Training Loss:1.991178446196906e-05 AVG Test Loss:3.079445329502082e-10 \n",
            "Epoch:27/30 AVG Training Loss:1.991177682445929e-05 AVG Test Loss:3.035534440452918e-10 \n",
            "Epoch:28/30 AVG Training Loss:1.9911770796857703e-05 AVG Test Loss:2.968193468318193e-10 \n",
            "Epoch:29/30 AVG Training Loss:1.991176748118142e-05 AVG Test Loss:2.9393972364408356e-10 \n",
            "Epoch:30/30 AVG Training Loss:1.9911762172034903e-05 AVG Test Loss:2.8935334241636427e-10 \n",
            "Fold 3\n",
            "Epoch:1/30 AVG Training Loss:1.8101598438709416e-05 AVG Test Loss:1.629783925988508e-05 \n",
            "Epoch:2/30 AVG Training Loss:1.8101595069086537e-05 AVG Test Loss:1.629783658663738e-05 \n",
            "Epoch:3/30 AVG Training Loss:1.810158955612712e-05 AVG Test Loss:1.6297832704340885e-05 \n",
            "Epoch:4/30 AVG Training Loss:1.8101581107511318e-05 AVG Test Loss:1.6297830941247135e-05 \n",
            "Epoch:5/30 AVG Training Loss:1.81015794323398e-05 AVG Test Loss:1.629782723766358e-05 \n",
            "Epoch:6/30 AVG Training Loss:1.810157430737967e-05 AVG Test Loss:1.629782419141999e-05 \n",
            "Epoch:7/30 AVG Training Loss:1.8101569298894276e-05 AVG Test Loss:1.62978205617482e-05 \n",
            "Epoch:8/30 AVG Training Loss:1.8101562454046772e-05 AVG Test Loss:1.6297819704256413e-05 \n",
            "Epoch:9/30 AVG Training Loss:1.810156133775686e-05 AVG Test Loss:1.6297814227277273e-05 \n",
            "Epoch:10/30 AVG Training Loss:1.8101556601616826e-05 AVG Test Loss:1.6297812557740446e-05 \n",
            "Epoch:11/30 AVG Training Loss:1.810155224211465e-05 AVG Test Loss:1.629781083170567e-05 \n",
            "Epoch:12/30 AVG Training Loss:1.810154951273251e-05 AVG Test Loss:1.629780835496278e-05 \n",
            "Epoch:13/30 AVG Training Loss:1.810154653904703e-05 AVG Test Loss:1.6297805185771834e-05 \n",
            "Epoch:14/30 AVG Training Loss:1.810154232506869e-05 AVG Test Loss:1.6297802791908406e-05 \n",
            "Epoch:15/30 AVG Training Loss:1.810154042370276e-05 AVG Test Loss:1.629780027384437e-05 \n",
            "Epoch:16/30 AVG Training Loss:1.8101536927711935e-05 AVG Test Loss:1.629779780058468e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.8101533427271126e-05 AVG Test Loss:1.629779531446305e-05 \n",
            "Epoch:18/30 AVG Training Loss:1.8101529967272495e-05 AVG Test Loss:1.6297793251884647e-05 \n",
            "Epoch:19/30 AVG Training Loss:1.8101527461375655e-05 AVG Test Loss:1.629779059314559e-05 \n",
            "Epoch:20/30 AVG Training Loss:1.81015246632324e-05 AVG Test Loss:1.6297789185027766e-05 \n",
            "Epoch:21/30 AVG Training Loss:1.8101521914569873e-05 AVG Test Loss:1.6297786872726326e-05 \n",
            "Epoch:22/30 AVG Training Loss:1.8101519534675468e-05 AVG Test Loss:1.6297785079087738e-05 \n",
            "Epoch:23/30 AVG Training Loss:1.810151600579651e-05 AVG Test Loss:1.6297783133621286e-05 \n",
            "Epoch:24/30 AVG Training Loss:1.8101513861337716e-05 AVG Test Loss:1.6297781420274817e-05 \n",
            "Epoch:25/30 AVG Training Loss:1.8101510954742633e-05 AVG Test Loss:1.6297780279977976e-05 \n",
            "Epoch:26/30 AVG Training Loss:1.8101509169384425e-05 AVG Test Loss:1.6297777145444104e-05 \n",
            "Epoch:27/30 AVG Training Loss:1.8101507240248934e-05 AVG Test Loss:1.6297775518135126e-05 \n",
            "Epoch:28/30 AVG Training Loss:1.810150481232116e-05 AVG Test Loss:1.6297773756089213e-05 \n",
            "Epoch:29/30 AVG Training Loss:1.8101502695446316e-05 AVG Test Loss:1.629777209328548e-05 \n",
            "Epoch:30/30 AVG Training Loss:1.8101500557583408e-05 AVG Test Loss:1.6297770674629785e-05 \n",
            "Fold 4\n",
            "Epoch:1/30 AVG Training Loss:1.8101536562188403e-05 AVG Test Loss:1.6297420995934745e-05 \n",
            "Epoch:2/30 AVG Training Loss:1.8101534979534514e-05 AVG Test Loss:1.6297420684001764e-05 \n",
            "Epoch:3/30 AVG Training Loss:1.810153287390183e-05 AVG Test Loss:1.6297417275950196e-05 \n",
            "Epoch:4/30 AVG Training Loss:1.8101530114488746e-05 AVG Test Loss:1.629741694781712e-05 \n",
            "Epoch:5/30 AVG Training Loss:1.810152898220864e-05 AVG Test Loss:1.62974169977665e-05 \n",
            "Epoch:6/30 AVG Training Loss:1.81015270368544e-05 AVG Test Loss:1.6297415228449074e-05 \n",
            "Epoch:7/30 AVG Training Loss:1.8101524624031773e-05 AVG Test Loss:1.6297414161475277e-05 \n",
            "Epoch:8/30 AVG Training Loss:1.810152325653527e-05 AVG Test Loss:1.629741317593844e-05 \n",
            "Epoch:9/30 AVG Training Loss:1.8101521574272895e-05 AVG Test Loss:1.629740967778596e-05 \n",
            "Epoch:10/30 AVG Training Loss:1.8101519561181013e-05 AVG Test Loss:1.6297408388212316e-05 \n",
            "Epoch:11/30 AVG Training Loss:1.8101518154858475e-05 AVG Test Loss:1.629740741271331e-05 \n",
            "Epoch:12/30 AVG Training Loss:1.8101516495121444e-05 AVG Test Loss:1.6297406296734172e-05 \n",
            "Epoch:13/30 AVG Training Loss:1.810151502800367e-05 AVG Test Loss:1.6297406141781427e-05 \n",
            "Epoch:14/30 AVG Training Loss:1.810151359265276e-05 AVG Test Loss:1.6297404939223436e-05 \n",
            "Epoch:15/30 AVG Training Loss:1.810151168561695e-05 AVG Test Loss:1.6297402231434544e-05 \n",
            "Epoch:16/30 AVG Training Loss:1.8101510418710355e-05 AVG Test Loss:1.6297400908141307e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.810150833148559e-05 AVG Test Loss:1.629740073654477e-05 \n",
            "Epoch:18/30 AVG Training Loss:1.810150743030008e-05 AVG Test Loss:1.6297399563987657e-05 \n",
            "Epoch:19/30 AVG Training Loss:1.8101506011016357e-05 AVG Test Loss:1.6297399086168284e-05 \n",
            "Epoch:20/30 AVG Training Loss:1.8101504271199323e-05 AVG Test Loss:1.6297398850589614e-05 \n",
            "Epoch:21/30 AVG Training Loss:1.8101503256463536e-05 AVG Test Loss:1.6297395924786564e-05 \n",
            "Epoch:22/30 AVG Training Loss:1.810150203791069e-05 AVG Test Loss:1.6297394762416173e-05 \n",
            "Epoch:23/30 AVG Training Loss:1.810150007679626e-05 AVG Test Loss:1.629739464760528e-05 \n",
            "Epoch:24/30 AVG Training Loss:1.8101499484839077e-05 AVG Test Loss:1.629739259941297e-05 \n",
            "Epoch:25/30 AVG Training Loss:1.8101498167964957e-05 AVG Test Loss:1.629739157358222e-05 \n",
            "Epoch:26/30 AVG Training Loss:1.8101496981292916e-05 AVG Test Loss:1.6297390685466746e-05 \n",
            "Epoch:27/30 AVG Training Loss:1.810149570811936e-05 AVG Test Loss:1.6297389584473273e-05 \n",
            "Epoch:28/30 AVG Training Loss:1.8101494324305327e-05 AVG Test Loss:1.6297388873378584e-05 \n",
            "Epoch:29/30 AVG Training Loss:1.8101493584923193e-05 AVG Test Loss:1.6297387831905144e-05 \n",
            "Epoch:30/30 AVG Training Loss:1.8101491999837638e-05 AVG Test Loss:1.629738708646632e-05 \n",
            "Fold 5\n",
            "Epoch:1/30 AVG Training Loss:1.9911614471854495e-05 AVG Test Loss:1.3677318993419794e-10 \n",
            "Epoch:2/30 AVG Training Loss:1.991161327790735e-05 AVG Test Loss:1.3795367236152097e-10 \n",
            "Epoch:3/30 AVG Training Loss:1.9911612156865806e-05 AVG Test Loss:1.3618789863195646e-10 \n",
            "Epoch:4/30 AVG Training Loss:1.9911611226113112e-05 AVG Test Loss:1.3615498428568443e-10 \n",
            "Epoch:5/30 AVG Training Loss:1.9911610250975888e-05 AVG Test Loss:1.3565750698210032e-10 \n",
            "Epoch:6/30 AVG Training Loss:1.9911609263955672e-05 AVG Test Loss:1.3374094437550613e-10 \n",
            "Epoch:7/30 AVG Training Loss:1.991160825298523e-05 AVG Test Loss:1.3266660135688587e-10 \n",
            "Epoch:8/30 AVG Training Loss:1.991160734074454e-05 AVG Test Loss:1.320357216451845e-10 \n",
            "Epoch:9/30 AVG Training Loss:1.9911606287671678e-05 AVG Test Loss:1.3151888129053674e-10 \n",
            "Epoch:10/30 AVG Training Loss:1.991160538222371e-05 AVG Test Loss:1.303374704715517e-10 \n",
            "Epoch:11/30 AVG Training Loss:1.9911604517789515e-05 AVG Test Loss:1.308689334248822e-10 \n",
            "Epoch:12/30 AVG Training Loss:1.991160365753793e-05 AVG Test Loss:1.290805934332525e-10 \n",
            "Epoch:13/30 AVG Training Loss:1.9911602375741355e-05 AVG Test Loss:1.2777385129820287e-10 \n",
            "Epoch:14/30 AVG Training Loss:1.991160187962996e-05 AVG Test Loss:1.288989054382128e-10 \n",
            "Epoch:15/30 AVG Training Loss:1.9911600865606087e-05 AVG Test Loss:1.2790767937805906e-10 \n",
            "Epoch:16/30 AVG Training Loss:1.991160019674744e-05 AVG Test Loss:1.2622489182057184e-10 \n",
            "Epoch:17/30 AVG Training Loss:1.991159909229309e-05 AVG Test Loss:1.256711195765271e-10 \n",
            "Epoch:18/30 AVG Training Loss:1.991159835201276e-05 AVG Test Loss:1.2464527769157168e-10 \n",
            "Epoch:19/30 AVG Training Loss:1.991159753255935e-05 AVG Test Loss:1.2381872494112842e-10 \n",
            "Epoch:20/30 AVG Training Loss:1.991159668642482e-05 AVG Test Loss:1.2440778253679112e-10 \n",
            "Epoch:21/30 AVG Training Loss:1.991159599700191e-05 AVG Test Loss:1.2383709160231e-10 \n",
            "Epoch:22/30 AVG Training Loss:1.9911595174001412e-05 AVG Test Loss:1.216907585057696e-10 \n",
            "Epoch:23/30 AVG Training Loss:1.991159440096273e-05 AVG Test Loss:1.2174523357429346e-10 \n",
            "Epoch:24/30 AVG Training Loss:1.9911593618704993e-05 AVG Test Loss:1.2029295743949135e-10 \n",
            "Epoch:25/30 AVG Training Loss:1.9911592893764835e-05 AVG Test Loss:1.2084080843722735e-10 \n",
            "Epoch:26/30 AVG Training Loss:1.9911592123025124e-05 AVG Test Loss:1.1928946675499323e-10 \n",
            "Epoch:27/30 AVG Training Loss:1.991159151821085e-05 AVG Test Loss:1.1861641970258041e-10 \n",
            "Epoch:28/30 AVG Training Loss:1.9911590819787967e-05 AVG Test Loss:1.180868141059148e-10 \n",
            "Epoch:29/30 AVG Training Loss:1.9911590154549893e-05 AVG Test Loss:1.175416182965126e-10 \n",
            "Epoch:30/30 AVG Training Loss:1.991158942205639e-05 AVG Test Loss:1.178111199138629e-10 \n",
            "Fold 6\n",
            "Epoch:1/30 AVG Training Loss:1.9911589276136635e-05 AVG Test Loss:1.1264820204227042e-10 \n",
            "Epoch:2/30 AVG Training Loss:1.9911588274775392e-05 AVG Test Loss:1.1416889515642844e-10 \n",
            "Epoch:3/30 AVG Training Loss:1.991158767695826e-05 AVG Test Loss:1.1454575640461576e-10 \n",
            "Epoch:4/30 AVG Training Loss:1.9911587010884396e-05 AVG Test Loss:1.1429842564116588e-10 \n",
            "Epoch:5/30 AVG Training Loss:1.9911586232335326e-05 AVG Test Loss:1.1426499830187947e-10 \n",
            "Epoch:6/30 AVG Training Loss:1.991158547934521e-05 AVG Test Loss:1.1455688956880386e-10 \n",
            "Epoch:7/30 AVG Training Loss:1.9911584795188538e-05 AVG Test Loss:1.1406559274096019e-10 \n",
            "Epoch:8/30 AVG Training Loss:1.9911584159402592e-05 AVG Test Loss:1.1459957256047885e-10 \n",
            "Epoch:9/30 AVG Training Loss:1.9911583587413776e-05 AVG Test Loss:1.1504681425683992e-10 \n",
            "Epoch:10/30 AVG Training Loss:1.991158298294902e-05 AVG Test Loss:1.1482170628608741e-10 \n",
            "Epoch:11/30 AVG Training Loss:1.9911582323627587e-05 AVG Test Loss:1.1521373166070291e-10 \n",
            "Epoch:12/30 AVG Training Loss:1.9911581729413426e-05 AVG Test Loss:1.1541246255532008e-10 \n",
            "Epoch:13/30 AVG Training Loss:1.9911581204740222e-05 AVG Test Loss:1.1656014559561374e-10 \n",
            "Epoch:14/30 AVG Training Loss:1.9911580558453314e-05 AVG Test Loss:1.1694142006264979e-10 \n",
            "Epoch:15/30 AVG Training Loss:1.991157990874269e-05 AVG Test Loss:1.1628308280082597e-10 \n",
            "Epoch:16/30 AVG Training Loss:1.9911579503640322e-05 AVG Test Loss:1.1665471757415776e-10 \n",
            "Epoch:17/30 AVG Training Loss:1.991157883059325e-05 AVG Test Loss:1.1786311865580417e-10 \n",
            "Epoch:18/30 AVG Training Loss:1.9911578320789145e-05 AVG Test Loss:1.1866555237555763e-10 \n",
            "Epoch:19/30 AVG Training Loss:1.991157782245931e-05 AVG Test Loss:1.182541855662971e-10 \n",
            "Epoch:20/30 AVG Training Loss:1.9911577228074058e-05 AVG Test Loss:1.18469855344708e-10 \n",
            "Epoch:21/30 AVG Training Loss:1.9911576716199136e-05 AVG Test Loss:1.1926401949652143e-10 \n",
            "Epoch:22/30 AVG Training Loss:1.9911576211232875e-05 AVG Test Loss:1.202183351690287e-10 \n",
            "Epoch:23/30 AVG Training Loss:1.9911575722082275e-05 AVG Test Loss:1.200379691979294e-10 \n",
            "Epoch:24/30 AVG Training Loss:1.9911575227556552e-05 AVG Test Loss:1.2070959506490358e-10 \n",
            "Epoch:25/30 AVG Training Loss:1.991157471268225e-05 AVG Test Loss:1.2153971826436802e-10 \n",
            "Epoch:26/30 AVG Training Loss:1.9911574201104422e-05 AVG Test Loss:1.2133562512779154e-10 \n",
            "Epoch:27/30 AVG Training Loss:1.991157370286663e-05 AVG Test Loss:1.2151101829353123e-10 \n",
            "Epoch:28/30 AVG Training Loss:1.9911573162933666e-05 AVG Test Loss:1.221787753831495e-10 \n",
            "Epoch:29/30 AVG Training Loss:1.991157259922094e-05 AVG Test Loss:1.2309840010850792e-10 \n",
            "Epoch:30/30 AVG Training Loss:1.9911572199464127e-05 AVG Test Loss:1.239130446820584e-10 \n",
            "Fold 7\n",
            "Epoch:1/30 AVG Training Loss:1.4481131203962548e-05 AVG Test Loss:4.889249874601964e-05 \n",
            "Epoch:2/30 AVG Training Loss:1.448112973960812e-05 AVG Test Loss:4.889249846754433e-05 \n",
            "Epoch:3/30 AVG Training Loss:1.4481129269878063e-05 AVG Test Loss:4.889249817780659e-05 \n",
            "Epoch:4/30 AVG Training Loss:1.4481128879770328e-05 AVG Test Loss:4.8892497841809564e-05 \n",
            "Epoch:5/30 AVG Training Loss:1.4481128056383359e-05 AVG Test Loss:4.889249749820747e-05 \n",
            "Epoch:6/30 AVG Training Loss:1.448112748854196e-05 AVG Test Loss:4.889249718073725e-05 \n",
            "Epoch:7/30 AVG Training Loss:1.4481127226987625e-05 AVG Test Loss:4.8892496836702624e-05 \n",
            "Epoch:8/30 AVG Training Loss:1.4481126519458215e-05 AVG Test Loss:4.8892496518428564e-05 \n",
            "Epoch:9/30 AVG Training Loss:1.4481125911211139e-05 AVG Test Loss:4.889249610090034e-05 \n",
            "Epoch:10/30 AVG Training Loss:1.4481125533525e-05 AVG Test Loss:4.889249577345315e-05 \n",
            "Epoch:11/30 AVG Training Loss:1.4481125066056607e-05 AVG Test Loss:4.889249545401378e-05 \n",
            "Epoch:12/30 AVG Training Loss:1.4481124602999045e-05 AVG Test Loss:4.889249513429433e-05 \n",
            "Epoch:13/30 AVG Training Loss:1.4481123981645458e-05 AVG Test Loss:4.8892494819778954e-05 \n",
            "Epoch:14/30 AVG Training Loss:1.4481123656815645e-05 AVG Test Loss:4.889249449337495e-05 \n",
            "Epoch:15/30 AVG Training Loss:1.4481123200977914e-05 AVG Test Loss:4.889249423736817e-05 \n",
            "Epoch:16/30 AVG Training Loss:1.448112272029081e-05 AVG Test Loss:4.889249389378751e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.4481122328449097e-05 AVG Test Loss:4.889249353577217e-05 \n",
            "Epoch:18/30 AVG Training Loss:1.4481121836558597e-05 AVG Test Loss:4.889249318054918e-05 \n",
            "Epoch:19/30 AVG Training Loss:1.448112136672822e-05 AVG Test Loss:4.8892492969050366e-05 \n",
            "Epoch:20/30 AVG Training Loss:1.4481121105971315e-05 AVG Test Loss:4.8892492608093306e-05 \n",
            "Epoch:21/30 AVG Training Loss:1.4481120837654836e-05 AVG Test Loss:4.889249232077946e-05 \n",
            "Epoch:22/30 AVG Training Loss:1.4481120338116193e-05 AVG Test Loss:4.889249202958839e-05 \n",
            "Epoch:23/30 AVG Training Loss:1.448111995570873e-05 AVG Test Loss:4.8892491710353226e-05 \n",
            "Epoch:24/30 AVG Training Loss:1.44811195247088e-05 AVG Test Loss:4.889249140452566e-05 \n",
            "Epoch:25/30 AVG Training Loss:1.448111909258298e-05 AVG Test Loss:4.889249124097091e-05 \n",
            "Epoch:26/30 AVG Training Loss:1.4481118833183733e-05 AVG Test Loss:4.889249087766331e-05 \n",
            "Epoch:27/30 AVG Training Loss:1.4481118451271587e-05 AVG Test Loss:4.8892490584344163e-05 \n",
            "Epoch:28/30 AVG Training Loss:1.4481118081901254e-05 AVG Test Loss:4.889249032603075e-05 \n",
            "Epoch:29/30 AVG Training Loss:1.4481117719674063e-05 AVG Test Loss:4.889249008862078e-05 \n",
            "Epoch:30/30 AVG Training Loss:1.4481117442074902e-05 AVG Test Loss:4.8892489751319386e-05 \n",
            "Fold 8\n",
            "Epoch:1/30 AVG Training Loss:1.8101436896978216e-05 AVG Test Loss:1.629733894098279e-05 \n",
            "Epoch:2/30 AVG Training Loss:1.810143648800624e-05 AVG Test Loss:1.6297338762031115e-05 \n",
            "Epoch:3/30 AVG Training Loss:1.8101436329691757e-05 AVG Test Loss:1.6297338606414724e-05 \n",
            "Epoch:4/30 AVG Training Loss:1.810143585279216e-05 AVG Test Loss:1.629733832840082e-05 \n",
            "Epoch:5/30 AVG Training Loss:1.8101435665422702e-05 AVG Test Loss:1.629733815531569e-05 \n",
            "Epoch:6/30 AVG Training Loss:1.8101435239356486e-05 AVG Test Loss:1.629733791251566e-05 \n",
            "Epoch:7/30 AVG Training Loss:1.8101434721021464e-05 AVG Test Loss:1.6297337600144133e-05 \n",
            "Epoch:8/30 AVG Training Loss:1.8101434567288365e-05 AVG Test Loss:1.6297337361725307e-05 \n",
            "Epoch:9/30 AVG Training Loss:1.810143399589217e-05 AVG Test Loss:1.629733710677233e-05 \n",
            "Epoch:10/30 AVG Training Loss:1.8101433751180388e-05 AVG Test Loss:1.6297336930547054e-05 \n",
            "Epoch:11/30 AVG Training Loss:1.8101433426733087e-05 AVG Test Loss:1.6297336708394595e-05 \n",
            "Epoch:12/30 AVG Training Loss:1.810143294013166e-05 AVG Test Loss:1.629733638555707e-05 \n",
            "Epoch:13/30 AVG Training Loss:1.810143263271612e-05 AVG Test Loss:1.6297336083251723e-05 \n",
            "Epoch:14/30 AVG Training Loss:1.8101432349933773e-05 AVG Test Loss:1.629733584549962e-05 \n",
            "Epoch:15/30 AVG Training Loss:1.8101432023765864e-05 AVG Test Loss:1.629733557743709e-05 \n",
            "Epoch:16/30 AVG Training Loss:1.8101431881484702e-05 AVG Test Loss:1.6297335342085362e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.810143143455232e-05 AVG Test Loss:1.6297335130523454e-05 \n",
            "Epoch:18/30 AVG Training Loss:1.81014311088108e-05 AVG Test Loss:1.6297334969285975e-05 \n",
            "Epoch:19/30 AVG Training Loss:1.810143083908097e-05 AVG Test Loss:1.6297334649102412e-05 \n",
            "Epoch:20/30 AVG Training Loss:1.8101430582361526e-05 AVG Test Loss:1.6297334379236014e-05 \n",
            "Epoch:21/30 AVG Training Loss:1.810143029847358e-05 AVG Test Loss:1.6297334139569773e-05 \n",
            "Epoch:22/30 AVG Training Loss:1.8101430007542244e-05 AVG Test Loss:1.62973339507691e-05 \n",
            "Epoch:23/30 AVG Training Loss:1.810142967715689e-05 AVG Test Loss:1.6297333713267957e-05 \n",
            "Epoch:24/30 AVG Training Loss:1.8101429446865057e-05 AVG Test Loss:1.6297333483110355e-05 \n",
            "Epoch:25/30 AVG Training Loss:1.8101429213033552e-05 AVG Test Loss:1.6297333248527684e-05 \n",
            "Epoch:26/30 AVG Training Loss:1.8101428926974435e-05 AVG Test Loss:1.6297333033355525e-05 \n",
            "Epoch:27/30 AVG Training Loss:1.8101428662881712e-05 AVG Test Loss:1.6297332827901663e-05 \n",
            "Epoch:28/30 AVG Training Loss:1.810142836099176e-05 AVG Test Loss:1.629733262285039e-05 \n",
            "Epoch:29/30 AVG Training Loss:1.810142808318832e-05 AVG Test Loss:1.6297332425302637e-05 \n",
            "Epoch:30/30 AVG Training Loss:1.810142785886654e-05 AVG Test Loss:1.629733220771218e-05 \n",
            "Fold 9\n",
            "Epoch:1/30 AVG Training Loss:1.8101427692572586e-05 AVG Test Loss:1.6297331406107455e-05 \n",
            "Epoch:2/30 AVG Training Loss:1.810142744334611e-05 AVG Test Loss:1.6297331314902444e-05 \n",
            "Epoch:3/30 AVG Training Loss:1.8101427160776875e-05 AVG Test Loss:1.6297331208440543e-05 \n",
            "Epoch:4/30 AVG Training Loss:1.8101426952173413e-05 AVG Test Loss:1.6297331054971332e-05 \n",
            "Epoch:5/30 AVG Training Loss:1.8101426676337933e-05 AVG Test Loss:1.6297330927501026e-05 \n",
            "Epoch:6/30 AVG Training Loss:1.810142642714131e-05 AVG Test Loss:1.629733079026769e-05 \n",
            "Epoch:7/30 AVG Training Loss:1.810142617307514e-05 AVG Test Loss:1.6297330583930896e-05 \n",
            "Epoch:8/30 AVG Training Loss:1.810142596174592e-05 AVG Test Loss:1.6297330348205642e-05 \n",
            "Epoch:9/30 AVG Training Loss:1.8101425697211658e-05 AVG Test Loss:1.629733017417923e-05 \n",
            "Epoch:10/30 AVG Training Loss:1.810142544373026e-05 AVG Test Loss:1.629733003420005e-05 \n",
            "Epoch:11/30 AVG Training Loss:1.8101425252702387e-05 AVG Test Loss:1.6297329843468395e-05 \n",
            "Epoch:12/30 AVG Training Loss:1.810142501647688e-05 AVG Test Loss:1.6297329670012182e-05 \n",
            "Epoch:13/30 AVG Training Loss:1.81014247596647e-05 AVG Test Loss:1.6297329489892872e-05 \n",
            "Epoch:14/30 AVG Training Loss:1.810142452210737e-05 AVG Test Loss:1.6297329321922827e-05 \n",
            "Epoch:15/30 AVG Training Loss:1.810142429273252e-05 AVG Test Loss:1.62973291323515e-05 \n",
            "Epoch:16/30 AVG Training Loss:1.8101424076697798e-05 AVG Test Loss:1.6297328961943355e-05 \n",
            "Epoch:17/30 AVG Training Loss:1.8101423816955196e-05 AVG Test Loss:1.629732883550311e-05 \n",
            "Epoch:18/30 AVG Training Loss:1.8101423591633383e-05 AVG Test Loss:1.6297328686288232e-05 \n",
            "Epoch:19/30 AVG Training Loss:1.81014233593363e-05 AVG Test Loss:1.629732853388614e-05 \n",
            "Epoch:20/30 AVG Training Loss:1.810142317550544e-05 AVG Test Loss:1.629732834220424e-05 \n",
            "Epoch:21/30 AVG Training Loss:1.810142297075782e-05 AVG Test Loss:1.629732815069333e-05 \n",
            "Epoch:22/30 AVG Training Loss:1.810142274678693e-05 AVG Test Loss:1.629732792782118e-05 \n",
            "Epoch:23/30 AVG Training Loss:1.8101422501129573e-05 AVG Test Loss:1.6297327788813026e-05 \n",
            "Epoch:24/30 AVG Training Loss:1.8101422267640242e-05 AVG Test Loss:1.629732762285324e-05 \n",
            "Epoch:25/30 AVG Training Loss:1.8101422086488585e-05 AVG Test Loss:1.6297327505350015e-05 \n",
            "Epoch:26/30 AVG Training Loss:1.8101421699124254e-05 AVG Test Loss:1.629732734819688e-05 \n",
            "Epoch:27/30 AVG Training Loss:1.8101421492891318e-05 AVG Test Loss:1.6297327188957402e-05 \n",
            "Epoch:28/30 AVG Training Loss:1.810142130602332e-05 AVG Test Loss:1.6297326983082897e-05 \n",
            "Epoch:29/30 AVG Training Loss:1.8101421081089835e-05 AVG Test Loss:1.6297326818057426e-05 \n",
            "Epoch:30/30 AVG Training Loss:1.810142089415446e-05 AVG Test Loss:1.6297326648394605e-05 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rtx7uAEk1CxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Find Best model of cross validation folds"
      ],
      "metadata": {
        "id": "oz_Kg-fV1DRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def findBestModelIndex(className, foldperf, k): # k=number of folds\n",
        "  loss = []\n",
        "  for f in range(0,k):\n",
        "    loss.append(sum(foldperf['fold{}'.format(f)]['train_loss']) + sum(foldperf['fold{}'.format(f)]['test_loss']))\n",
        "  \n",
        "  min_value = np.min(loss)\n",
        "  min_index = loss.index(min_value)\n",
        "  print(className, \"best model index:\", min_index,\"and value:\", min_value)"
      ],
      "metadata": {
        "id": "WxH5H-28HQhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "findBestModelIndex(\"Normal\", normal_foldperf, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjwRVt33fzh8",
        "outputId": "af904758-565c-4395-c810-9069bb530b22"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal best model index: 9 and value: 6.1163509167782e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/ckpts/Normal_cross_fold_9.pth /content/drive/\"My Drive\"/AE/e3-kfold-new/best_models/Normal.pth"
      ],
      "metadata": {
        "id": "SEbJxOfIgAOb"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3mNAuONzf_kT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/ckpts/Normla_cross_fold_3.pth /content/drive/\"My Drive\"/AE/e3-kfold-new/best_models/Attacker.pth"
      ],
      "metadata": {
        "id": "gWC-quaSf3mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "findBestModelIndex(\"Attacker\", attacker_foldperf, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9DBENsu0Ik-",
        "outputId": "28a96de3-0474-4c5d-e3cb-1f81cfb5080f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attacker best model index: 3 and value: 0.00041561010339621185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/ckpts/Attacker_cross_fold_3.pth /content/drive/\"My Drive\"/AE/e3-kfold-new/best_models/Attacker.pth"
      ],
      "metadata": {
        "id": "bYyiTTTCECxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "findBestModelIndex(\"Victim\", victim_foldperf, k)"
      ],
      "metadata": {
        "id": "Sden48fYOU3h",
        "outputId": "5bdc9536-8e95-4ba3-d88d-940e24185ccf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Victim best model index: 5 and value: 0.0005973509285028913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/ckpts/Victim_cross_fold_5.pth /content/drive/\"My Drive\"/AE/e3-kfold-new/best_models/Victim.pth"
      ],
      "metadata": {
        "id": "lGgdvElDHpvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aV2bQJibb7VP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dY_x8yCw1NS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training performance"
      ],
      "metadata": {
        "id": "-UyvDp_x1Nyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainingPerfprmance(className, foldperf, k):\n",
        "  testl_f,tl_f = [],[]\n",
        "\n",
        "  for f in range(0, k):\n",
        "      tl_f.append(np.mean(foldperf['fold{}'.format(f)]['train_loss']))\n",
        "      testl_f.append(np.mean(foldperf['fold{}'.format(f)]['test_loss']))\n",
        "\n",
        "  print('Performance of', className, 'in {} fold cross validation'.format(k))\n",
        "  print(\"Average Training Loss: {} \\t Average Test Loss: {}\".format(np.mean(tl_f),np.mean(testl_f)))\n",
        "  print()\n"
      ],
      "metadata": {
        "id": "ZDdQNrNSz2EB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingPerfprmance(\"Normal\", normal_foldperf, k)"
      ],
      "metadata": {
        "id": "bC9cKG78b7QM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e7ed9a1-1ead-4a94-cae8-44dd91631279"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance of Normal in 10 fold cross validation\n",
            "Average Training Loss: 0.0003274487429321198 \t Average Test Loss: 0.00020558926182749748\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainingPerfprmance(\"Attacker\", attacker_foldperf, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH1KsFmJ0gn6",
        "outputId": "d1682d3b-de4c-4ef6-8c6c-95beed5624d2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance of Attacker in 10 fold cross validation\n",
            "Average Training Loss: 0.00023103662095637673 \t Average Test Loss: 0.00011846412644365276\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loss chart"
      ],
      "metadata": {
        "id": "WPRbWY2O1V4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, ax = plt.subplots(1,1,figsize=(15,10))\n",
        "ax.set_title('Loss')\n",
        "ax.plot(normal_metrics['train_loss'])\n",
        "ax.plot(normal_metrics['val_loss'])"
      ],
      "metadata": {
        "id": "fdzhMrU9zdWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, ax = plt.subplots(1,1,figsize=(15,10))\n",
        "ax.set_title('Loss')\n",
        "ax.plot(attacker_metrics['train_loss'])\n",
        "ax.plot(attacker_metrics['val_loss'])"
      ],
      "metadata": {
        "id": "ynPzQ34Pb7MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_uG1DrX54Cw"
      },
      "source": [
        "_, ax = plt.subplots(1,1,figsize=(15,10))\n",
        "ax.set_title('Loss')\n",
        "ax.plot(victim_metrics['train_loss'])\n",
        "ax.plot(victim_metrics['val_loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4wxStgSuHIJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LsEPGMDLHIEC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}